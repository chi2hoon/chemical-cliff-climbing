import streamlit as st
import pandas as pd
import datetime
import os
import json
import zipfile
import io
from modules.cheminformatics import find_activity_cliffs
from modules.visualization import visualize_structure_difference, smiles_to_image_b64
from modules.llm_handler import generate_hypothesis, evaluate_hypothesis, revise_hypothesis, create_activity_summary
from modules.io_utils import load_smiles_activity_csv, save_hypothesis_to_md, parse_hypothesis_md

# --- Helper Functions ---

def get_openai_api_key_from_file():
    try:
        with open("openAI_key.txt", "r") as f:
            return f.read().strip()
    except FileNotFoundError:
        return None

def format_hypothesis_for_markdown(data: dict) -> str:
    """ì£¼ì–´ì§„ ê°€ì„¤ ë°ì´í„°(dict)ë¥¼ ê°€ë…ì„± ì¢‹ì€ ë§ˆí¬ë‹¤ìš´ ë° HTML ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    md_lines = []

    # ê¸°ë³¸ ì •ë³´
    md_lines.append(f"### ğŸ† ì£¼ìš” ê°€ì„¤: {data.get('primary_hypothesis', 'N/A')}")
    md_lines.append(f"- **ë” í™œì„±ì´ ë†’ì€ í™”í•©ë¬¼:** `{data.get('more_active', 'N/A')}`")
    md_lines.append(f"- **í™œì„±ë„ ë³€í™” ì„¤ëª…:** {data.get('delta_pAct_explained', 'N/A')}")
    md_lines.append(f"- **ì‹ ë¢°ë„:** {data.get('confidence', 0.0) * 100:.1f}%")
    md_lines.append("\n")

    # ê¸°ì „ ë¶„ì„
    md_lines.append("### ğŸ”¬ ê¸°ì „ ë¶„ì„")
    rationale = data.get('mechanistic_rationale', {})
    for key, value in rationale.items():
        if value and value not in ["N/A", "ì„ íƒ"]:
            md_lines.append(f"- **{key.replace('_', ' ').title()}:** {value}")
    md_lines.append("\n")

    # ì„¤ê³„ ì œì•ˆ (HTML í…Œì´ë¸”ë¡œ ë³€ê²½)
    md_lines.append("### ğŸ’¡ ê²€ì¦ì„ ìœ„í•œ ë¶„ì ì„¤ê³„ ì œì•ˆ")
    suggestions = data.get('design_suggestions', [])
    if suggestions:
        html_table = "<table><thead><tr><th>Design (SMILES)</th><th>Structure</th><th>Expected Effect</th><th>Rationale</th><th>Validation Metric</th></tr></thead><tbody>"
        for s in suggestions:
            smiles = s.get('design', '')
            b64_img = smiles_to_image_b64(smiles) if smiles else ''
            img_tag = f'<img src="data:image/png;base64,{b64_img}" width="200">' if b64_img else ''
            
            html_table += f"<tr>"
            html_table += f"<td>`{smiles}`</td>"
            html_table += f"<td>{img_tag}</td>"
            html_table += f"<td>{s.get('expected_effect', 'N/A')}</td>"
            html_table += f"<td>{s.get('rationale', 'N/A')}</td>"
            html_table += f"<td>{s.get('validation_metric', 'N/A')}</td>"
            html_table += "</tr>"
        html_table += "</tbody></table>"
        md_lines.append(html_table)
    md_lines.append("\n")

    # ë°˜ëŒ€ ê°€ì„¤
    md_lines.append("### ğŸ¤” ë°˜ëŒ€ ê°€ì„¤")
    counter_hypotheses = data.get('counter_hypotheses', [])
    for i, counter in enumerate(counter_hypotheses, 1):
        md_lines.append(f"{i}. {counter}")
    md_lines.append("\n")

    # ADMET ìœ„í—˜ì„±
    md_lines.append("### âš ï¸ ADMET ìœ„í—˜ì„± ì˜ˆì¸¡")
    admet_flags = data.get('admet_flags', [])
    for flag in admet_flags:
        md_lines.append(f"- {flag}")
    md_lines.append("\n")
    
    # ê°€ì • ë° í•œê³„
    md_lines.append("### ğŸ“‹ ê°€ì • ë° í•œê³„")
    assumptions = data.get('assumptions_and_limits', [])
    for assumption in assumptions:
        md_lines.append(f"- {assumption}")

    return "\n".join(md_lines)

def format_evaluation_for_markdown(data: dict) -> str:
    """Evaluation ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    md_lines = []
    summary = data.get('summary', {})
    md_lines.append(f"### ğŸ“ í‰ê°€ ìš”ì•½")
    md_lines.append(f"- **íŒì •:** {summary.get('verdict', 'N/A')}")
    md_lines.append(f"- **ì‹¬ì‚¬ ë°©ë²•:** {summary.get('method_sketch', 'N/A')}")
    md_lines.append("\n")

    details = data.get('detailed_solution', {})
    md_lines.append("### ğŸ” ìƒì„¸ í‰ê°€")
    md_lines.append(f"- **ê¸°ë³¸ ì¼ì¹˜ì„±:** {details.get('consistency_check', 'N/A')}")
    md_lines.append(f"- **ê´€ì ë³„ ê²€ì¦:** {details.get('aspect_validation', 'N/A')}")
    md_lines.append(f"- **ë°˜ëŒ€ ê°€ì„¤ ê²€í† :** {details.get('counter_hypothesis_review', 'N/A')}")
    md_lines.append(f"- **ì„¤ê³„ ì œì•ˆ ê²€í† :** {details.get('design_suggestion_review', 'N/A')}")
    md_lines.append(f"- **ì¶”ê°€ í•„ìš” ìš”ì†Œ:** {details.get('additional_requirements', 'N/A')}")
    return "\n".join(md_lines)

# --- Streamlit App ---

st.set_page_config(layout="centered")
st.title("ğŸ”¬ SAR ë¶„ì„ ë° ê°€ì„¤ ìƒì„±/í‰ê°€/ìˆ˜ì • ìë™í™” ë„êµ¬")
st.write("ë¶„ì êµ¬ì¡°ì™€ í™œì„± ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì¡°-í™œì„± ê´€ê³„(SAR) ë¶„ì„ ë° ê°€ì„¤ ìƒì„±, í‰ê°€, ìˆ˜ì •ì„ ìë™í™”í•©ë‹ˆë‹¤.")

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "1. ë°ì´í„° ì—…ë¡œë“œ",
    "2. Activity Cliff ë¶„ì„",
    "3. ê°€ì„¤ ìƒì„±",
    "4. ê°€ì„¤ ê´€ë¦¬",
    "5. ê°€ì„¤ í‰ê°€ ë° ìˆ˜ì •"
])

with tab1:
    st.header("1. ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ë¶„ì êµ¬ì¡°(SMILES)ì™€ í™œì„± ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="csv")

    if uploaded_file is not None:
        try:
            df, suggestion = load_smiles_activity_csv(uploaded_file)
            st.success("íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            st.error(f"CSV ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            df = None

        if df is not None:
            st.subheader("ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df.head())
            st.caption("ìë™ ì¸ì‹ëœ ì»¬ëŸ¼ ì œì•ˆê°’ì„ í™•ì¸í•˜ì„¸ìš”. í•„ìš” ì‹œ ë³€ê²½ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            st.session_state['auto_suggestion'] = suggestion

        st.session_state['df'] = df

with tab2:
    st.header("2. Activity Cliff ë¶„ì„")
    if 'df' in st.session_state and st.session_state['df'] is not None:
        df = st.session_state['df']
        
        col1, col2 = st.columns(2)
        with col1:
            auto = st.session_state.get('auto_suggestion', {})
            smiles_col_default = auto.get('smiles_col') if auto.get('smiles_col') in df.columns else None
            activity_col_default = auto.get('activity_col') if auto.get('activity_col') in df.columns else None

            smiles_col = st.selectbox("SMILES ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:", df.columns, index=(list(df.columns).index(smiles_col_default) if smiles_col_default else 0))
            activity_col = st.selectbox("í™œì„±ë„ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:", df.columns, index=(list(df.columns).index(activity_col_default) if activity_col_default else (1 if len(df.columns) > 1 else 0)))

        with col2:
            similarity_threshold = st.slider("êµ¬ì¡° ìœ ì‚¬ë„ ì„ê³„ê°’ (Tanimoto)", 0.7, 1.0, 0.85, 0.01)
            activity_diff_threshold = st.number_input("í™œì„±ë„ ì°¨ì´ ì„ê³„ê°’", min_value=0.0, value=1.0, step=0.1)

        activity_assumption = st.radio(
            "í™œì„±ë„ ë°ì´í„°ì˜ ì˜ë¯¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
            ('ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)', 'ê°’ì´ ë‚®ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Lower is better)'),
            key='activity_assumption'
        )

        if st.button("Activity Cliff ë¶„ì„ ì‹¤í–‰"):
            with st.spinner("Activity Cliffë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                work_df = df.copy()
                work_df = work_df.dropna(subset=[activity_col])
                work_df = work_df.reset_index(drop=True)
                
                cliff_df = find_activity_cliffs(
                    work_df,
                    smiles_col=smiles_col,
                    activity_col=activity_col,
                    similarity_threshold=similarity_threshold,
                    activity_diff_threshold=activity_diff_threshold,
                    higher_is_better= (st.session_state.activity_assumption == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)')
                )
            
            st.success(f"{len(cliff_df)}ê°œì˜ Activity Cliff ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
            st.dataframe(cliff_df)
            st.session_state['cliff_df'] = cliff_df

            # í™œì„±ë„ ì§€í‘œì— ëŒ€í•œ ìš”ì•½ ì •ë³´ í‘œì‹œ
            summary_text = create_activity_summary(activity_col, (st.session_state.activity_assumption == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)'))
            st.markdown("---")
            st.markdown(summary_text)
    else:
        st.info("1. ë°ì´í„° ì—…ë¡œë“œ íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("3. ê²°ê³¼ ì‹œê°í™” ë° ê°€ì„¤ ìƒì„±")
    if 'cliff_df' in st.session_state and not st.session_state['cliff_df'].empty:
        cliff_df = st.session_state['cliff_df']
        
        st.subheader("ë¶„ì„í•  Activity Cliff ìŒ ì„ íƒ")
        st.dataframe(cliff_df)
        selected_indices = st.multiselect("ë¶„ì„ ë° ì‹œê°í™”í•  Activity Cliff ìŒì˜ ì¸ë±ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:", cliff_df.index)
        
        if selected_indices:
            openai_api_key = get_openai_api_key_from_file()
            if not openai_api_key:
                st.warning("LLM ê°€ì„¤ ìƒì„±ì„ ìœ„í•´ openAI_key.txt íŒŒì¼ì— API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.session_state['openai_api_key'] = openai_api_key
                st.success("API í‚¤ê°€ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

                if st.button("ì„ íƒëœ ìŒì— ëŒ€í•œ ê°€ì„¤ ìƒì„±"):
                    output_dir = "hypotheses"
                    os.makedirs(output_dir, exist_ok=True)

                    for i in selected_indices:
                        row = cliff_df.loc[i]
                        st.subheader(f"ë¶„ì„ ìŒ #{i}")
                        
                        img = visualize_structure_difference(
                            smiles1=row['SMILES_1'],
                            smiles2=row['SMILES_2'],
                            legend1=f"SMILES: {row['SMILES_1']}\nActivity: {row['Activity_1']:.2f}",
                            legend2=f"SMILES: {row['SMILES_2']}\nActivity: {row['Activity_2']:.2f}"
                        )
                        st.image(img, caption=f"ìœ ì‚¬ë„: {row['Similarity']:.3f} | í™œì„±ë„ ì°¨ì´: {row['Activity_Diff']:.2f}")

                        with st.spinner(f"ìŒ #{i}ì— ëŒ€í•œ LLM ê°€ì„¤ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                            higher_is_better = st.session_state.get('activity_assumption') == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)'
                            
                            # ê°€ì •ì— ë”°ë¼ ê³ í™œì„±/ì €í™œì„± ë¶„ì ê²°ì •
                            if (higher_is_better and row['Activity_1'] > row['Activity_2']) or \
                               (not higher_is_better and row['Activity_1'] < row['Activity_2']):
                                high_act_smiles, high_act_val = row['SMILES_1'], row['Activity_1']
                                low_act_smiles, low_act_val = row['SMILES_2'], row['Activity_2']
                            else:
                                high_act_smiles, high_act_val = row['SMILES_2'], row['Activity_2']
                                low_act_smiles, low_act_val = row['SMILES_1'], row['Activity_1']

                            json_response = generate_hypothesis(
                                api_key=openai_api_key,
                                smiles1=low_act_smiles,
                                activity1=low_act_val,
                                smiles2=high_act_smiles,
                                activity2=high_act_val,
                                structural_difference_description=f"í™”í•©ë¬¼ 1({low_act_smiles})ê³¼ í™”í•©ë¬¼ 2({high_act_smiles})ì˜ êµ¬ì¡°ì  ì°¨ì´ì .",
                                similarity=row['Similarity']
                            )
                            
                            try:
                                hypothesis_data = json.loads(json_response)
                                display_md = format_hypothesis_for_markdown(hypothesis_data)
                                file_header = f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{low_act_smiles}` (í™œì„±ë„: {low_act_val:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{high_act_smiles}` (í™œì„±ë„: {high_act_val:.2f})\n\n---\n"
                                file_md = file_header + display_md
                                st.markdown(file_md, unsafe_allow_html=True)
                                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"hypothesis_pair_{i}_{timestamp}.md"
                                filepath = os.path.join(output_dir, filename)
                                save_hypothesis_to_md(file_md, filepath)
                                st.success(f"ê°€ì„¤ì´ '{filepath}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            except json.JSONDecodeError:
                                st.error("LLM ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì›ë³¸ ì‘ë‹µì„ í‘œì‹œí•©ë‹ˆë‹¤:")
                                st.text(json_response)
    else:
        st.info("2. Activity Cliff ë¶„ì„ íƒ­ì—ì„œ ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

with tab4:
    st.header("ğŸ“œ ì €ì¥ëœ ê°€ì„¤ ê´€ë¦¬ (ë³´ê¸°/ë‹¤ìš´ë¡œë“œ)")
    hypotheses_dir = "hypotheses"

    if st.button("ğŸ”„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("ì•„ì§ ì €ì¥ëœ ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        if not files:
            st.info("ì €ì¥ëœ ê°€ì„¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            selected_file = st.selectbox("í™•ì¸í•  ê°€ì„¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:", files)

            if selected_file:
                filepath = os.path.join(hypotheses_dir, selected_file)
                try:
                    with open(filepath, "r", encoding="utf-8") as file:
                        content = file.read()
                    
                    st.markdown("---")
                    st.subheader(f"ğŸ“„ {selected_file}")
                    st.markdown(content, unsafe_allow_html=True)

                    st.download_button(
                        label=f"'{selected_file}' ë‹¤ìš´ë¡œë“œ",
                        data=content,
                        file_name=selected_file,
                        mime="text/markdown"
                    )

                except Exception as e:
                    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

with tab5:
    st.header("ğŸ”„ ê°€ì„¤ í‰ê°€ ë° ìˆ˜ì •")
    hypotheses_dir = "hypotheses"

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("í‰ê°€í•  ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        hypothesis_files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        # --- 1. ê°€ì„¤ íŒŒì¼ ëª©ë¡ í‘œì‹œ ---
        st.subheader("ğŸ“‹ ê°€ì„¤ ëª©ë¡")
        selected_file = st.radio(
            "í‰ê°€í•  ê°€ì„¤ì„ ì„ íƒí•˜ì„¸ìš”:", 
            hypothesis_files, 
            key="selected_hypothesis_file",
            label_visibility="collapsed"
        )
        st.markdown("---")

        # --- 2. ì„ íƒëœ ê°€ì„¤ ë‚´ìš© ë° í‰ê°€/ìˆ˜ì • ---
        if selected_file:
            st.subheader(f"ğŸ“„ ì›ë³¸ ê°€ì„¤: {selected_file}")
            filepath = os.path.join(hypotheses_dir, selected_file)

            try:
                with open(filepath, "r", encoding="utf-8") as file:
                    content = file.read()
                
                parsed_data = parse_hypothesis_md(content)
                if not all(parsed_data.values()):
                    st.error(f"íŒŒì¼({selected_file})ì—ì„œ ë¶„ì ì •ë³´ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.stop()

                # ì›ë³¸ ê°€ì„¤ í‘œì‹œ
                st.markdown(content, unsafe_allow_html=True)
                st.markdown("---")

                # --- ê°€ì„¤ í‰ê°€ ---
                eval_container = st.container(border=True)
                with eval_container:
                    st.subheader("ğŸ”¬ ê°€ì„¤ í‰ê°€")
                    eval_key = f"eval_{selected_file}"
                    
                    if st.button("ê°€ì„¤ í‰ê°€ ì‹¤í–‰", key=f"eval_btn_{selected_file}"):
                        openai_api_key = get_openai_api_key_from_file()
                        if not openai_api_key:
                            st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                        else:
                            with st.spinner("LLMì´ ê°€ì„¤ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                                eval_response = evaluate_hypothesis(
                                    api_key=openai_api_key,
                                    hypothesis_text=parsed_data['hypothesis_body'],
                                    smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                    smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                    structural_difference_description=""
                                )
                                st.session_state[eval_key] = eval_response
                                # ìƒˆë¡œìš´ í‰ê°€ê°€ ì‹œì‘ë˜ë©´ ì´ì „ ìˆ˜ì • ê²°ê³¼ëŠ” ì‚­ì œ
                                if f"revise_{selected_file}" in st.session_state:
                                    del st.session_state[f"revise_{selected_file}"]
                    
                    if eval_key in st.session_state:
                        st.markdown("##### í‰ê°€ ê²°ê³¼")
                        try:
                            eval_data = json.loads(st.session_state[eval_key])
                            formatted_eval_md = format_evaluation_for_markdown(eval_data)
                            st.markdown(formatted_eval_md, unsafe_allow_html=True)

                            # í‰ê°€ ê²°ê³¼ ì €ì¥ ì„¹ì…˜
                            st.markdown("---")
                            evaluations_dir = "evaluations"
                            os.makedirs(evaluations_dir, exist_ok=True)
                            
                            base_filename = selected_file.replace(".md", "")
                            eval_filename = f"{base_filename}_Eval.md"
                            
                            content_to_save = f"# ì›ë³¸ ê°€ì„¤: {selected_file}\n\n{content}\n\n---\n\n# ê°€ì„¤ í‰ê°€ ê²°ê³¼\n\n{formatted_eval_md}"
                            eval_filepath = os.path.join(evaluations_dir, eval_filename)
                            save_hypothesis_to_md(content_to_save, eval_filepath)
                            st.success(f"í‰ê°€ ê²°ê³¼ê°€ '{eval_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.toast("í‰ê°€ ì €ì¥ ì™„ë£Œ!")

                        except json.JSONDecodeError:
                            st.error("LLM í‰ê°€ ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
                            st.text(st.session_state[eval_key])

                # --- ê°€ì„¤ ìˆ˜ì • ë° ì €ì¥ ---
                if eval_key in st.session_state:
                    revise_container = st.container(border=True)
                    with revise_container:
                        st.subheader("âœï¸ í‰ê°€ ê¸°ë°˜ ê°€ì„¤ ìˆ˜ì •")
                        revise_key = f"revise_{selected_file}"

                        if st.button("í‰ê°€ ê¸°ë°˜ìœ¼ë¡œ ê°€ì„¤ ìˆ˜ì •", key=f"revise_btn_{selected_file}"):
                            openai_api_key = get_openai_api_key_from_file()
                            if not openai_api_key:
                                st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                            else:
                                with st.spinner("LLMì´ ê°€ì„¤ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                                    revise_response = revise_hypothesis(
                                        api_key=openai_api_key,
                                        original_hypothesis_text=parsed_data['hypothesis_body'],
                                        review_findings=st.session_state[eval_key],
                                        smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                        smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                        structural_difference_description=""
                                    )
                                    st.session_state[revise_key] = revise_response
                        
                        if revise_key in st.session_state:
                            st.markdown("##### ìˆ˜ì •ëœ ê°€ì„¤")
                            try:
                                revised_data = json.loads(st.session_state[revise_key])
                                display_md = format_hypothesis_for_markdown(revised_data)
                                st.markdown(display_md, unsafe_allow_html=True)

                                # ìˆ˜ì •ëœ ê°€ì„¤ ì €ì¥ ì„¹ì…˜
                                st.markdown("---")
                                st.subheader("ğŸ’¾ ìˆ˜ì •ëœ ê°€ì„¤ ì €ì¥")
                                
                                file_header = f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{parsed_data['smiles1']}` (í™œì„±ë„: {parsed_data['activity1']:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{parsed_data['smiles2']}` (í™œì„±ë„: {parsed_data['activity2']:.2f})\n\n---"
                                final_md_to_save = file_header + display_md

                                new_filename = f"revised_{selected_file}"
                                new_filepath = os.path.join(hypotheses_dir, new_filename)
                                save_hypothesis_to_md(final_md_to_save, new_filepath)
                                st.success(f"ìˆ˜ì •ëœ ê°€ì„¤ì´ '{new_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.toast("ì €ì¥ ì™„ë£Œ!")

                            except json.JSONDecodeError:
                                st.error("LLM ìˆ˜ì • ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
                                st.text(st.session_state[revise_key])

            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


