import streamlit as st
import pandas as pd
import datetime
import os
import json
import zipfile
import io
from modules.cheminformatics import find_activity_cliffs
from modules.visualization import visualize_structure_difference, smiles_to_image_b64
from modules.llm_handler import generate_hypothesis, evaluate_hypothesis, revise_hypothesis, create_activity_summary
from modules.context_builder import build_pair_context
from modules.io_utils import (
    load_smiles_activity_csv,
    save_hypothesis_to_md,
    parse_hypothesis_md,
    load_gold_data,
    get_available_gold_years,
    get_available_targets,
    get_available_panel_ids,
    get_all_available_panels_and_years,
    get_cell_lines_for_panel
)

# --- Helper Functions ---

def get_openai_api_key_from_file():
    # 1) í™˜ê²½ë³€ìˆ˜ ìš°ì„ 
    env_key = os.getenv("OPENAI_API_KEY")
    if env_key and env_key.strip():
        return env_key.strip()
    # 2) í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬(base)ì—ì„œ íƒìƒ‰
    try:
        with open("openAI_key.txt", "r") as f:
            return f.read().strip()
    except FileNotFoundError:
        pass
    # 3) ë ˆí¬ ë£¨íŠ¸(../)ì—ì„œë„ íƒìƒ‰
    try:
        here = os.path.dirname(os.path.abspath(__file__))
        root_key = os.path.abspath(os.path.join(here, os.pardir, "openAI_key.txt"))
        if os.path.exists(root_key):
            with open(root_key, "r") as f:
                return f.read().strip()
    except Exception:
        pass
    return None


# --- Token usage helpers ---
def _init_token_usage_state():
    if 'token_usage' not in st.session_state:
        st.session_state['token_usage'] = {
            'calls': [],
            'totals': {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0},
        }


def _reset_token_usage():
    st.session_state['token_usage'] = {
        'calls': [],
        'totals': {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0},
    }


def _add_token_usage(phase: str, model: str, usage: dict):
    _init_token_usage_state()
    usage = usage or {}
    pt = int(usage.get('prompt_tokens', 0) or 0)
    ct = int(usage.get('completion_tokens', 0) or 0)
    tt = int(usage.get('total_tokens', pt + ct) or (pt + ct))
    st.session_state['token_usage']['calls'].append({
        'phase': phase, 'model': model, 'prompt_tokens': pt, 'completion_tokens': ct, 'total_tokens': tt,
    })
    st.session_state['token_usage']['totals']['prompt_tokens'] += pt
    st.session_state['token_usage']['totals']['completion_tokens'] += ct
    st.session_state['token_usage']['totals']['total_tokens'] += tt


def _show_last_and_total_tokens():
    tu = st.session_state.get('token_usage')
    if not tu or not tu.get('calls'):
        return
    last = tu['calls'][-1]
    totals = tu['totals']
    st.info(
        f"í† í° ì‚¬ìš©ëŸ‰ â€” ì´ë²ˆ í˜¸ì¶œ({last['phase']}, {last['model']}): "
        f"prompt {last['prompt_tokens']}, completion {last['completion_tokens']}, total {last['total_tokens']} | "
        f"ëˆ„ì : prompt {totals['prompt_tokens']}, completion {totals['completion_tokens']}, total {totals['total_tokens']}"
    )

def format_hypothesis_for_markdown(data: dict) -> str:
    """ì£¼ì–´ì§„ ê°€ì„¤ ë°ì´í„°(dict)ë¥¼ ê°€ë…ì„± ì¢‹ì€ ë§ˆí¬ë‹¤ìš´ ë° HTML ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    md_lines = []

    # ê¸°ë³¸ ì •ë³´
    md_lines.append(f"### ğŸ† ì£¼ìš” ê°€ì„¤: {data.get('primary_hypothesis', 'N/A')}")
    md_lines.append(f"- **ë” í™œì„±ì´ ë†’ì€ í™”í•©ë¬¼:** `{data.get('more_active', 'N/A')}`")
    md_lines.append(f"- **í™œì„±ë„ ë³€í™” ì„¤ëª…:** {data.get('delta_pAct_explained', 'N/A')}")
    md_lines.append(f"- **ì‹ ë¢°ë„:** {data.get('confidence', 0.0) * 100:.1f}%")
    md_lines.append("\n")

    # ê¸°ì „ ë¶„ì„
    md_lines.append("### ğŸ”¬ ê¸°ì „ ë¶„ì„")
    rationale = data.get('mechanistic_rationale', {})
    for key, value in rationale.items():
        if value and value not in ["N/A", "ì„ íƒ"]:
            md_lines.append(f"- **{key.replace('_', ' ').title()}:** {value}")
    md_lines.append("\n")

    # ì„¤ê³„ ì œì•ˆ (HTML í…Œì´ë¸”ë¡œ ë³€ê²½)
    md_lines.append("### ğŸ’¡ ê²€ì¦ì„ ìœ„í•œ ë¶„ì ì„¤ê³„ ì œì•ˆ")
    suggestions = data.get('design_suggestions', [])
    if suggestions:
        html_table = "<table><thead><tr><th>Design (SMILES)</th><th>Structure</th><th>Expected Effect</th><th>Rationale</th><th>Validation Metric</th></tr></thead><tbody>"
        for s in suggestions:
            smiles = s.get('design', '')
            b64_img = smiles_to_image_b64(smiles) if smiles else ''
            img_tag = f'<img src="data:image/png;base64,{b64_img}" width="200">' if b64_img else ''
            
            html_table += f"<tr>"
            html_table += f"<td>`{smiles}`</td>"
            html_table += f"<td>{img_tag}</td>"
            html_table += f"<td>{s.get('expected_effect', 'N/A')}</td>"
            html_table += f"<td>{s.get('rationale', 'N/A')}</td>"
            html_table += f"<td>{s.get('validation_metric', 'N/A')}</td>"
            html_table += "</tr>"
        html_table += "</tbody></table>"
        md_lines.append(html_table)
    md_lines.append("\n")

    # ë°˜ëŒ€ ê°€ì„¤
    md_lines.append("### ğŸ¤” ë°˜ëŒ€ ê°€ì„¤")
    counter_hypotheses = data.get('counter_hypotheses', [])
    for i, counter in enumerate(counter_hypotheses, 1):
        md_lines.append(f"{i}. {counter}")
    md_lines.append("\n")

    # ADMET ìœ„í—˜ì„±
    md_lines.append("### âš ï¸ ADMET ìœ„í—˜ì„± ì˜ˆì¸¡")
    admet_flags = data.get('admet_flags', [])
    for flag in admet_flags:
        md_lines.append(f"- {flag}")
    md_lines.append("\n")
    
    # ê°€ì • ë° í•œê³„
    md_lines.append("### ğŸ“‹ ê°€ì • ë° í•œê³„")
    assumptions = data.get('assumptions_and_limits', [])
    for assumption in assumptions:
        md_lines.append(f"- {assumption}")

    return "\n".join(md_lines)

def format_evaluation_for_markdown(data: dict) -> str:
    """Evaluation ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    md_lines = []
    summary = data.get('summary', {})
    md_lines.append(f"### ğŸ“ í‰ê°€ ìš”ì•½")
    md_lines.append(f"- **íŒì •:** {summary.get('verdict', 'N/A')}")
    md_lines.append(f"- **ì‹¬ì‚¬ ë°©ë²•:** {summary.get('method_sketch', 'N/A')}")
    md_lines.append("\n")

    details = data.get('detailed_solution', {})
    md_lines.append("### ğŸ” ìƒì„¸ í‰ê°€")
    md_lines.append(f"- **ê¸°ë³¸ ì¼ì¹˜ì„±:** {details.get('consistency_check', 'N/A')}")
    md_lines.append(f"- **ê´€ì ë³„ ê²€ì¦:** {details.get('aspect_validation', 'N/A')}")
    md_lines.append(f"- **ë°˜ëŒ€ ê°€ì„¤ ê²€í† :** {details.get('counter_hypothesis_review', 'N/A')}")
    md_lines.append(f"- **ì„¤ê³„ ì œì•ˆ ê²€í† :** {details.get('design_suggestion_review', 'N/A')}")
    md_lines.append(f"- **ì¶”ê°€ í•„ìš” ìš”ì†Œ:** {details.get('additional_requirements', 'N/A')}")
    return "\n".join(md_lines)

# --- Streamlit App ---

st.set_page_config(layout="centered")
st.title("ğŸ”¬ SAR ë¶„ì„ ë° ê°€ì„¤ ìƒì„±/í‰ê°€/ìˆ˜ì • ìë™í™” ë„êµ¬")
st.write("ë¶„ì êµ¬ì¡°ì™€ í™œì„± ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì¡°-í™œì„± ê´€ê³„(SAR) ë¶„ì„ ë° ê°€ì„¤ ìƒì„±, í‰ê°€, ìˆ˜ì •ì„ ìë™í™”í•©ë‹ˆë‹¤.")


tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "1. ë°ì´í„°ì…‹ ì„ íƒ",
    "2. Activity Cliff ë¶„ì„",
    "3. ê°€ì„¤ ìƒì„±",
    "4. ê°€ì„¤ ê´€ë¦¬",
    "5. ê°€ì„¤ í‰ê°€ ë° ìˆ˜ì •",
    "6. ìë™ ê°€ì„¤ ìˆ˜ì •"
])

with tab1:
    st.header("1. ë°ì´í„° ë¡œë“œ")
    st.markdown("í‘œì¤€í™”ëœ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")


    # ë°ì´í„°ì…‹ ì„ íƒ (ì•± íŒŒì¼ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³ ì • ê²½ë¡œ êµ¬ì„±)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_root = os.path.join(base_dir, "data")
    available_years_all = get_available_gold_years(data_root)

    if not available_years_all:
        st.warning("ë¶„ì„ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ `PYTHONPATH=base python -m pipeline.cli gold --years 2017 2018`ë¡œ ìƒì„±í•˜ì„¸ìš”.")
    else:
        # íŒ¨ë„ ì´ë¦„ ë§¤í•‘
        panel_names_map = {
            "blca": "ë°©ê´‘ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "prad": "ì „ë¦½ì„ ì•”ì„¸í¬ì£¼ íŒ¨ë„", 
            "luad": "íì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "brca": "ìœ ë°©ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "heme": "í˜ˆì•¡ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "paad": "ì·Œì¥ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "coad": "ëŒ€ì¥ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "misc12": "ë‡Œì•”/ê¸°íƒ€ íŒ¨ë„",
            "misc13": "ê¸°íƒ€ íŒ¨ë„"
        }

        # ë…„ë„(ì™¼ìª½) - ë³´ê¸°ì¶•/í•„í„°(ì˜¤ë¥¸ìª½)
        col_year, col_right = st.columns([1, 2])


        with col_year:
            selected_year = st.selectbox("ğŸ“… ë°ì´í„°ì…‹ ë…„ë„", sorted(available_years_all), index=0)


        available_panels = get_available_panel_ids(selected_year, data_root)
        available_targets = get_available_targets(selected_year, data_root)
        view_options = []
        if available_panels:
            view_options.append("ì„¸í¬ íŒ¨ë„ ë³´ê¸°")
        if available_targets:
            view_options.append("íƒ€ê¹ƒ ë³´ê¸°")
        if not view_options:
            view_options = ["íƒ€ê¹ƒ ë³´ê¸°"]

        selected_view = st.radio("ë³´ê¸° ì¶•", view_options, index=0, horizontal=True)

        selected_panel = None
        selected_target = None

        with col_right:
            if selected_view == "ì„¸í¬ íŒ¨ë„ ë³´ê¸°" and available_panels:
                panel_display_options = ["ì „ì²´ íŒ¨ë„"]
                panel_id_to_display = {"ì „ì²´ íŒ¨ë„": None}
                for panel_id in sorted(available_panels):
                    display_name = panel_names_map.get(panel_id, panel_id)
                    display_option = f"{panel_id} ({display_name})" if str(display_name).strip() != str(panel_id).strip() else f"{display_name}"
                    panel_id_to_display[display_option] = panel_id
                selected_panel_display = st.selectbox("ğŸ§¬ íŒ¨ë„ ì„ íƒ", panel_display_options, index=0)
                selected_panel = panel_id_to_display[selected_panel_display]
            else:
                targets = available_targets
                target_display_options = ["ì „ì²´ íƒ€ê¹ƒ"] + targets
                selected_target_display = st.selectbox("ğŸ¯ íƒ€ê¹ƒ ì„ íƒ", target_display_options, index=0)
                selected_target = None if selected_target_display == "ì „ì²´ íƒ€ê¹ƒ" else selected_target_display


        # ì„¸í¬ì£¼ ì…€ë ‰í„° (íŒ¨ë„ ì„ íƒ ì‹œ)
        selected_cell_line = None
        if selected_panel:
            cell_lines = get_cell_lines_for_panel(selected_year, selected_panel, data_root)
            if cell_lines:
                selected_cell_line = st.selectbox("ğŸ§« ì„¸í¬ì£¼ ì„ íƒ", ["ì „ì²´ ì„¸í¬ì£¼"] + cell_lines, index=0)
                if selected_cell_line == "ì „ì²´ ì„¸í¬ì£¼":
                    selected_cell_line = None

        # ë¡œë“œ ë²„íŠ¼ - selected_yearê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ
        if selected_year:
            st.markdown("### ğŸš€ ë°ì´í„° ë¡œë“œ")
            # ë°ì´í„° ì„¤ëª… í† ê¸€(ì „ì²´ ë„ˆë¹„)
            _desc = None
            if str(selected_year) == "2017":
                _desc = (
                    "2017: êµ­ë¦½ì•”ì„¼í„°Â·í•œêµ­í™”í•™ì—° íŠ¹í—ˆ(KR101920163B1, PCT/WO2018021849A1) ë¶€ì† í‘œë¥¼ ì •ë¦¬í•œ ì„¸íŠ¸ì…ë‹ˆë‹¤. ì•”ì¢…ë³„ ì„¸í¬ì£¼ íŒ¨ë„ì—ì„œ ì„¸í¬ë…ì„± ICâ‚…â‚€(Î¼M)ì´ ë³´ê³ ë˜ë©°, ì¼ë¶€ í‘œì—” ë„ìŠ¤Â·ì¹˜ì‚¬ìœ¨Â·ì‹¬ë°•ë³€í™” ê°™ì€ ë³´ì¡° ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤.\n\n"
                    "í™œìš© ê°€ì´ë“œ\n"
                    "- ì„¸í¬ íŒ¨ë„ ë³´ê¸°ì—ì„œ ì›í•˜ëŠ” íŒ¨ë„/ì„¸í¬ì£¼ë¥¼ ì„ íƒí•´ ë™ì¼ ë§¥ë½ì—ì„œ êµ¬ì¡°â€“í™œì„± ë¹„êµë¥¼ ì§„í–‰í•˜ì„¸ìš”. pAct ëª¨ë“œ(-log10[M])ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
                    "- Activity Cliff: ìœ ì‚¬ë„ ì„ê³„ê°’(â‰¥0.85)ê³¼ Î”pAct ì„ê³„ê°’ì„ ì¡°ì •í•˜ë©° ì„ íƒì„± ë†’ì€ ìŒì„ ì„ ë³„í•˜ì„¸ìš”.\n"
                    "- ë³´ì¡° ì •ë³´(ë„ìŠ¤Â·ì¹˜ì‚¬ìœ¨Â·ì‹¬ë°•ë³€í™”)ëŠ” í›„ë³´ ìš°ì„ ìˆœìœ„ íŒë‹¨ ì‹œ ì•ˆì „ì„±/ë…ì„± ë¦¬ìŠ¤í¬ ê´€ì ì—ì„œ í•¨ê»˜ ì°¸ê³ í•˜ì„¸ìš”."
                )
            elif str(selected_year) == "2018":
                _desc = (
                    "2018: PCT/EP2018/056824, WO 2018/172250 ë¶€ì† í‘œë¥¼ ì •ë¦¬í•œ ì„¸íŠ¸ì…ë‹ˆë‹¤. Rasâ€“SOS1 ìƒí˜¸ì‘ìš©(HTRF, Assay 1~3)ê³¼ EGFR kinase ê²°ê³¼ê°€ í¬í•¨ë˜ë©°, ê°’ì€ ICâ‚…â‚€ ë˜ëŠ” 20 ÂµM ë‹¨ì¼ ë†ë„ì˜ % ì–µì œë¡œ ë³´ê³ ë©ë‹ˆë‹¤.\n\n"
                    "í™œìš© ê°€ì´ë“œ\n"
                    "- Rasâ€“SOS1 ê´€ë ¨ ì§€í‘œë¥¼ ì„ íƒí•´ ê³„ì—´ ë‚´ SARì„ í™•ì¸í•˜ì„¸ìš”. pAct ëª¨ë“œ(-log10[M])ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
                    "- EGFR ì„ íƒì„±: EGFR ê°’ì„ í•¨ê»˜ í™•ì¸í•´ ì˜¤í”„íƒ€ê¹ƒ ë¯¼ê° í›„ë³´ë¥¼ ë¹ ë¥´ê²Œ ê°€ë ¤ë‚´ì„¸ìš”.\n"
                    "- 20 ÂµM ë‹¨ì¼ë†ë„ % ì–µì œëŠ” ë³´ì¡° ì§€í‘œë¡œë§Œ ì°¸ê³ í•˜ê³ , ICâ‚…â‚€ì™€ í•¨ê»˜ í•´ì„í•˜ì„¸ìš”."
                )
            elif str(selected_year) == "2020":
                _desc = (
                    "2020: íŠ¹í—ˆ WO2020132269 ë¶€ì† í‘œë¥¼ ì •ë¦¬í•œ USP1 ì €í•´ì œ ì„¸íŠ¸ì…ë‹ˆë‹¤. Examples(êµ¬ì¡°)Â·Intermediates/BB(ë¶€í’ˆ)ì™€ í•¨ê»˜, íš¨ì†Œ ì €í•´ ICâ‚…â‚€ê°€ ë“±ê¸‰ ê¸°í˜¸(+, ++, +++, ++++)ë¡œ ë³´ê³ ë©ë‹ˆë‹¤. ì•±ì—ì„œ ë“±ê¸‰â†’ìˆ˜ì¹˜ë¡œ ë³€í™˜ë˜ì–´ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                    "Â· ë¯¼ê°ë„(Table 5): <316 nM ê¸°ì¤€ Yes/No ë¼ë²¨(íŒ¨ë„/ìœ ì „í˜• ìˆ˜ì¤€).\n"
                    "Â· ADME(Table 6~7): ìš©í•´ë„(pH 2.0/7.4)Â·ê°„ ë¯¸ì†Œì²´ ì•ˆì •ì„±(HLM/RLM tâ‚/â‚‚)ì„ +/<ì„ê³„Â·++/â‰¥ì„ê³„(10 Î¼M, 25 min) ë“±ê¸‰ìœ¼ë¡œ ìš”ì•½.\n"
                    "Â· Asterisk ì˜ˆì™¸: ì´ë¯¸ì§€â€“SMILES ë¶ˆì¼ì¹˜ êµì •í‘œì˜ NEW SMILESê°€ ì ìš©ë©ë‹ˆë‹¤.\n\n"
                    "í™œìš© ê°€ì´ë“œ\n"
                    "- íƒ€ê¹ƒì„ â€˜usp1â€™ë¡œ ë‘ê³  Activity Cliff ë¶„ì„ì—ì„œ pAct ëª¨ë“œë¡œ ë¹„êµí•˜ì„¸ìš”(ë“±ê¸‰â†’ìˆ˜ì¹˜ ë³€í™˜ ë°˜ì˜).\n"
                    "- í›„ë³´ ìš°ì„ ìˆœìœ„: ìƒìœ„ ë“±ê¸‰(ì €ë†ë„) ì¤‘ì‹¬ìœ¼ë¡œ Î”pActë¥¼ í™•ì¸í•´ êµ¬ì¡°â€“í™œì„± ì°¨ì´ë¥¼ í•´ì„í•˜ì„¸ìš”.\n"
                    "- ë¯¼ê°ë„/ADME ìš”ì•½ì€ í’ˆì§ˆ/ì í•©ì„±ì˜ ë³´ì¡° ê¸°ì¤€ìœ¼ë¡œ ì°¸ê³ í•˜ë˜, ì§ì ‘ ë¹„êµì— ê³¼ì‹ í•˜ì§€ ë§ˆì„¸ìš”."
                )
            elif str(selected_year) == "2021":
                _desc = (
                    "2021: íŠ¹í—ˆ WO2021163344 ë¶€ì† í‘œë¥¼ ì •ë¦¬í•œ PRMT5 ì €í•´ì œ ì„¸íŠ¸ì…ë‹ˆë‹¤. Table 19ì— ìƒí™”í•™ Ki(nM, Method A/B)ì™€ ì„¸í¬ ì¦ì‹ ICâ‚…â‚€(Î¼M, HCT116 MTAP-null/WT)ì´ ìˆ˜ì¹˜ë¡œ ë³´ê³ ë˜ë©° ì¼ë¶€ëŠ” â€˜>10â€™ ê°™ì€ ê²€ì—´ í‘œê¸°ê°€ ìˆìŠµë‹ˆë‹¤. ê°’ê³¼ ë‹¨ìœ„ëŠ” ì•±ì—ì„œ ì¼ê´€ í‘œê¸°ë¡œ í‘œì‹œë©ë‹ˆë‹¤.\n\n"
                    "í™œìš© ê°€ì´ë“œ\n"
                    "- íš¨ì†Œâ€“ì„¸í¬ ìƒê´€: íƒ€ê¹ƒ ë³´ê¸°(prmt5, Ki A/B)ì™€ ì„¸í¬ íŒ¨ë„ ë³´ê¸°(HCT116: MTAP-null/WT)ë¥¼ ê°ê° ì„ íƒí•´ ìƒê´€/ê²©ì°¨ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n"
                    "- ì„ íƒì„± ì§€í‘œ: MTAP-null vs WTì˜ Î”pICâ‚…â‚€ ë˜ëŠ” (WT/null) ë¹„ìœ¨ë¡œ ì„ íƒì„±ì„ ê³„ì‚°í•´ ìš°ì„  í›„ë³´ë¥¼ ì¶”ë¦½ë‹ˆë‹¤.\n"
                    "- Method ìš°ì„ ìˆœìœ„: Aë¥¼ ìš°ì„  ì‚¬ìš©(ê²°ì¸¡ ì‹œ B). â€˜>10â€™ ê²€ì—´ê°’ì€ í•˜í•œìœ¼ë¡œë§Œ í•´ì„í•´ ë¹„êµ ì‹œ ì£¼ì˜í•˜ì„¸ìš”."
                )
            with st.expander("ë°ì´í„° ì„¤ëª…", expanded=False):
                st.markdown(_desc or "í•´ë‹¹ ì—°ë„ì— ëŒ€í•œ ì„¤ëª…ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
            load_text = f"{selected_year}ë…„ ë°ì´í„° ë¡œë“œ"
            if selected_panel:
                panel_name = panel_names_map.get(selected_panel, selected_panel)
                load_text += f" ({panel_name})"
            elif selected_target:
                load_text += f" (target: {selected_target})"

            if st.button(f"ğŸ“Š {load_text}", type="primary", use_container_width=True):
                try:
                    with st.spinner(f"{selected_year}ë…„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                        df_gold = load_gold_data(
                            year=selected_year,
                            data_root=data_root,
                            panel_id=(selected_panel if selected_view == "ì„¸í¬ íŒ¨ë„ ë³´ê¸°" else None),
                            cell_line=(selected_cell_line if selected_view == "ì„¸í¬ íŒ¨ë„ ë³´ê¸°" else None),
                            target_id=(selected_target if selected_view == "íƒ€ê¹ƒ ë³´ê¸°" else None)
                        )

                        if df_gold.empty:
                            if selected_panel:
                                st.error(f"{selected_year}ë…„ {selected_panel} íŒ¨ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            elif selected_target:
                                st.error(f"{selected_year}ë…„ target '{selected_target}' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.error(f"{selected_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.session_state['df'] = df_gold
                            st.session_state['auto_suggestion'] = {"smiles_col": "SMILES", "activity_col": "Activity"}
                            
                            success_msg = f"{selected_year}ë…„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ {len(df_gold)}ê°œ ë ˆì½”ë“œ"
                            if selected_panel:
                                success_msg += f" ({panel_names_map.get(selected_panel, selected_panel)})"
                            elif selected_target:
                                success_msg += f" (target: {selected_target})"
                            
                            st.success(success_msg)
                            st.dataframe(df_gold.head())

                            # ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ë³´ í‘œì‹œ
                            st.info("**ë°ì´í„° ìŠ¤í‚¤ë§ˆ:**\n"
                                   "â€¢ SMILES: í‘œì¤€í™”ëœ ìºë…¸ë‹ˆì»¬ SMILES\n"
                                   "â€¢ Activity: í‘œì¤€í™”ëœ í™œì„±ë„ ê°’ (value_std)\n"
                                   "â€¢ ë©”íƒ€ë°ì´í„°: assay_id, panel_id/target_id, cell_line, inchikey ë“±")

                except Exception as e:
                    st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")


with tab2:
    st.header("2. Activity Cliff ë¶„ì„")
    if 'df' in st.session_state and st.session_state['df'] is not None:
        df = st.session_state['df']
        
        # (í‘œì‹œ ì œê±°) ë‹¨ìœ„ ë¶„í¬ ìš”ì•½

        # ì»¬ëŸ¼ ìë™ ì„ íƒ(ê³ ì •): Gold ìŠ¤í‚¤ë§ˆ ê°€ì •í•˜ì— ìë™ ê²°ì •
        smiles_col = 'SMILES' if 'SMILES' in df.columns else df.columns[0]
        activity_col = 'Activity' if 'Activity' in df.columns else ( 'value_std' if 'value_std' in df.columns else (df.columns[1] if len(df.columns) > 1 else df.columns[0]))
        # (í‘œì‹œ ì œê±°) ìë™ ì„ íƒëœ ì»¬ëŸ¼ ì•ˆë‚´

        col1, col2 = st.columns(2)
        with col1:
            scale_choice = st.selectbox("í™œì„±ë„ ìŠ¤ì¼€ì¼", ["ì›ë³¸(ë‹¨ìœ„ ìœ ì§€)", "pAct (-log10[M])"], index=1)
            # ìŠ¤ì¼€ì¼ì— ë”°ë¼ í™œì„±ë„ ì˜ë¯¸ ìë™ ì„¤ì •(UI ë¹„ë…¸ì¶œ)
            if scale_choice == "pAct (-log10[M])":
                st.session_state['activity_assumption'] = 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)'
                st.caption("í™œì„±ë„ ì˜ë¯¸: pAct ìŠ¤ì¼€ì¼ â†’ ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ")
            else:
                st.session_state['activity_assumption'] = 'ê°’ì´ ë‚®ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Lower is better)'
                st.caption("í™œì„±ë„ ì˜ë¯¸: ì›ë³¸(IC50 ë“±) ìŠ¤ì¼€ì¼ â†’ ê°’ì´ ë‚®ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ")

        with col2:
            similarity_threshold = st.slider("êµ¬ì¡° ìœ ì‚¬ë„ ì„ê³„ê°’ (Tanimoto)", 0.7, 1.0, 0.85, 0.01)
            # ìŠ¤ì¼€ì¼ë³„ Î” ê¸°ë³¸ê°’: pActëŠ” ê´€ë¡€ì ìœ¼ë¡œ 2.0 ê¶Œì¥
            default_diff = 2.0 if scale_choice == "pAct (-log10[M])" else 1.0
            step = 0.1 if scale_choice == "pAct (-log10[M])" else 0.1
            fmt = "%0.2f" if scale_choice == "pAct (-log10[M])" else "%f"

        # (UI ìˆ¨ê¹€) í™œì„±ë„ ì˜ë¯¸ëŠ” ìœ„ ìŠ¤ì¼€ì¼ ì„ íƒì— ì˜í•´ ìë™ ì„¤ì •ë¨

        # --- í”„ë¦¬ë·°: ìœ ì‚¬ë„ë§Œ ì ìš©í•œ ë¶„í¬ ì‹œê°í™” ë° Î” ì„ê³„ê°’ ì„ íƒ ---
        # ìŠ¤ì¼€ì¼ ë³€í™˜ ì ìš©(í”„ë¦¬ë·°ì™€ ë¶„ì„ ëª¨ë‘ì—ì„œ ì¬ì‚¬ìš©)
        work_df = df.copy()
        work_df = work_df.dropna(subset=[activity_col]).reset_index(drop=True)
        chosen_activity_col = activity_col
        if scale_choice == "pAct (-log10[M])":
            unit_col = "unit_std" if "unit_std" in work_df.columns else None
            def _to_m(val, unit):
                try:
                    v = float(val)
                except Exception:
                    return None
                # ë‹¨ìœ„ ì •ê·œí™”(ì†Œë¬¸ì, Âµâ†’u ì¹˜í™˜)
                u = (str(unit) if unit is not None else "").strip()
                u_norm = u.replace("Âµ", "u").strip().lower()
                if u_norm == "m":
                    return v
                if u_norm == "mm":
                    return v * 1e-3
                if u_norm == "um":
                    return v * 1e-6
                if u_norm == "nm":
                    return v * 1e-9
                if u_norm == "pm":
                    return v * 1e-12
                # % ë“± ë¹„ë†ë„ ë‹¨ìœ„ëŠ” pAct ê³„ì‚° ëŒ€ìƒì—ì„œ ì œì™¸
                if u_norm in {"%", "percent", "pct"}:
                    return None
                # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° ë³´ìˆ˜ì ìœ¼ë¡œ uM ê°€ì •(í˜¸í™˜ì„± ìœ ì§€)
                return v * 1e-6
            def _to_pact(val_m):
                try:
                    import math
                    if val_m is None or float(val_m) <= 0:
                        return None
                    return -math.log10(float(val_m))
                except Exception:
                    return None
            vals_m = [ _to_m(work_df.iloc[i][activity_col], (work_df.iloc[i][unit_col] if unit_col else "uM")) for i in range(len(work_df)) ]
            pact = [ _to_pact(x) for x in vals_m ]
            work_df["Activity_pAct"] = pact
            work_df = work_df[pd.Series(work_df["Activity_pAct"]).notna()].reset_index(drop=True)
            chosen_activity_col = "Activity_pAct"

        # í”„ë¦¬ë·° ìŒ(Î” í•„í„° ë¯¸ì ìš©) â€” ë™ì¼ íŒŒë¼ë¯¸í„°ì—ì„œ ì¬ì‚¬ìš©ë˜ë„ë¡ ì„¸ì…˜ ìºì‹œ
        _cache_key = (
            "pairs_preview",
            int(similarity_threshold * 1000),
            chosen_activity_col,
            len(work_df),
        )
        prev_cache = st.session_state.get("_preview_cache", {})
        preview_df = None
        if prev_cache.get("key") == _cache_key:
            preview_df = prev_cache.get("df")
        if preview_df is None:
            preview_df = find_activity_cliffs(
                work_df,
                smiles_col=smiles_col,
                activity_col=chosen_activity_col,
                similarity_threshold=similarity_threshold,
                activity_diff_threshold=0.0,
                higher_is_better=(st.session_state.activity_assumption == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)')
            )
            st.session_state["_preview_cache"] = {"key": _cache_key, "df": preview_df}

        # Î” ì„ê³„ê°’ ì…ë ¥(íˆíŠ¸ë§µ ë³´ê¸° ì „ì— ê¸°ë³¸ê°’ ì‚°ì •)
        try:
            import numpy as _np
            q95 = float(preview_df["Activity_Diff"].quantile(0.95)) if len(preview_df) else default_diff
            max_for_slider = max(0.1, q95)
        except Exception:
            max_for_slider = default_diff
        activity_diff_threshold = st.slider(
            "í™œì„±ë„ ì°¨ì´ ì„ê³„ê°’",
            min_value=0.0,
            max_value=float(max_for_slider),
            value=float(min(default_diff, max_for_slider)),
            step=float(step)
        )

        # --- ë‹¨ì¼ íˆíŠ¸ë§µ ì˜ì—­(í”„ë¦¬ë·°/ê²°ê³¼ í† ê¸€) ---
        try:
            import altair as alt
            import pandas as _pd
            # ê²°ê³¼ê°€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìœ¼ë©´ í† ê¸€ ì œê³µ
            has_result = ('cliff_df' in st.session_state) and (st.session_state['cliff_df'] is not None) and (len(st.session_state['cliff_df']) > 0)
            options = ["í”„ë¦¬ë·°(ìœ ì‚¬ë„ë§Œ ì ìš©)"] + (["ê²°ê³¼(ì„ê³„ê°’ ëª¨ë‘ ì ìš©)"] if has_result else [])
            src_choice = st.radio("ì‹œê°í™” ì†ŒìŠ¤", options, horizontal=True, index=0, key="viz_source_choice_main")
            viz_df = preview_df if src_choice.startswith("í”„ë¦¬ë·°") else st.session_state['cliff_df']

            total_pairs = len(viz_df)
            mask_sel = (viz_df["Similarity"] >= similarity_threshold) & (viz_df["Activity_Diff"] >= activity_diff_threshold)
            selected_pairs = int(mask_sel.sum())
            ratio = (selected_pairs / total_pairs * 100.0) if total_pairs else 0.0
            m1, m2, m3 = st.columns(3)
            m1.metric("ì „ì²´ ìŒ ìˆ˜", f"{total_pairs:,}")
            m2.metric("ì„ íƒ ì˜ì—­ ìŒ ìˆ˜", f"{selected_pairs:,}")
            m3.metric("ë¹„ìœ¨(%)", f"{ratio:0.1f}")

            base = alt.Chart(viz_df)
            heat = base.mark_rect().encode(
                alt.X("Similarity:Q", bin=alt.Bin(maxbins=30), scale=alt.Scale(domain=[0.7, 1.0])),
                alt.Y("Activity_Diff:Q", bin=alt.Bin(maxbins=30)),
                alt.Color("count():Q", scale=alt.Scale(scheme="magma")),
                tooltip=[alt.Tooltip("count():Q", title="Count")]
            ).properties(height=320)
            v_rule = alt.Chart(_pd.DataFrame({"x": [similarity_threshold]})).mark_rule(color="#00FFFF", strokeDash=[6,4]).encode(x="x:Q")
            h_rule = alt.Chart(_pd.DataFrame({"y": [activity_diff_threshold]})).mark_rule(color="#00FFFF", strokeDash=[6,4]).encode(y="y:Q")
            st.altair_chart((heat + v_rule + h_rule).resolve_scale(color="independent"), use_container_width=True)
        except Exception:
            import numpy as _np
            st.info("ì‹œê°í™” ì—”ì§„(Altair) ì‚¬ìš©ì´ ì–´ë ¤ì›Œ ê°„ë‹¨í•œ ì‚°ì ë„ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            src = preview_df
            if ('cliff_df' in st.session_state) and len(st.session_state['cliff_df']) > 0:
                src = st.session_state['cliff_df']
            sample = src.sample(min(len(src), 5000), random_state=42) if len(src) > 5000 else src
            st.scatter_chart(sample[["Similarity", "Activity_Diff"]])

        if st.button("Activity Cliff ë¶„ì„ ì‹¤í–‰"):
            with st.spinner("Activity Cliffë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # work_df / chosen_activity_colëŠ” í”„ë¦¬ë·° ë‹¨ê³„ì—ì„œ ì´ë¯¸ ê³„ì‚°ë¨

                cliff_df = find_activity_cliffs(
                    work_df,
                    smiles_col=smiles_col,
                    activity_col=chosen_activity_col,
                    similarity_threshold=similarity_threshold,
                    activity_diff_threshold=activity_diff_threshold,
                    higher_is_better= (st.session_state.activity_assumption == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)')
                )
            
            st.success(f"{len(cliff_df)}ê°œì˜ Activity Cliff ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
            # IUPAC ë§¤í•‘(í‘œì‹œìš©)
            try:
                base_df = st.session_state.get('df', pd.DataFrame())
                name_map = {}
                if len(base_df) > 0 and 'SMILES' in base_df.columns:
                    if 'iupac_name' in base_df.columns:
                        tmp = base_df[['SMILES','iupac_name']].drop_duplicates()
                        name_map = {str(r['SMILES']): (str(r['iupac_name']).strip() if str(r['iupac_name']).strip() else None) for _, r in tmp.iterrows()}
                def _name_or_smiles(s):
                    s = str(s)
                    n = name_map.get(s)
                    return n if n and n.lower() != 'nan' else s
                display_df = cliff_df.copy()
                display_df['IUPAC_1'] = display_df['SMILES_1'].map(_name_or_smiles)
                display_df['IUPAC_2'] = display_df['SMILES_2'].map(_name_or_smiles)
                # í‘œì‹œ ì»¬ëŸ¼ ì¬ë°°ì¹˜ ë° ì •ë ¬(Î”, sim ë‚´ë¦¼ì°¨ìˆœ)
                cols = ['IUPAC_1','Activity_1','IUPAC_2','Activity_2','Similarity','Activity_Diff','SMILES_1','SMILES_2']
                cols = [c for c in cols if c in display_df.columns]
                display_df = display_df[cols].sort_values(by=['Activity_Diff','Similarity'], ascending=[False, False]).reset_index(drop=True)
                # 1-based ì¸ë±ìŠ¤
                display_df.index = range(1, len(display_df) + 1)
                display_df.index.name = 'Pair #'
                st.dataframe(display_df, use_container_width=True)
                try:
                    csv_bytes = display_df.to_csv(index=True).encode('utf-8')
                    st.download_button(
                        label="ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                        data=csv_bytes,
                        file_name="activity_cliffs.csv",
                        mime="text/csv",
                        use_container_width=True,
                    )
                except Exception:
                    pass
            except Exception:
                # ë¬¸ì œê°€ ìˆìœ¼ë©´ ì›ë³¸ í‘œë¼ë„ ì œê³µ
                df0 = cliff_df.copy().sort_values(by=['Activity_Diff','Similarity'], ascending=[False, False]).reset_index(drop=True)
                df0.index = range(1, len(df0) + 1)
                df0.index.name = 'Pair #'
                st.dataframe(df0, use_container_width=True)

            st.session_state['cliff_df'] = cliff_df

            # í™œì„±ë„ ì§€í‘œì— ëŒ€í•œ ìš”ì•½ ì •ë³´ í‘œì‹œ
            summary_text = create_activity_summary(activity_col, (st.session_state.activity_assumption == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)'))
            st.markdown("---")
            st.markdown(summary_text)

            # (íˆíŠ¸ë§µì€ ìƒë‹¨ì˜ ë‹¨ì¼ ì˜ì—­ì—ì„œ ì´ë¯¸ ì œê³µ)
    else:
        st.info("1. ìƒë‹¨ì—ì„œ Gold ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")

with tab3:
    st.header("3. ê²°ê³¼ ì‹œê°í™” ë° ê°€ì„¤ ìƒì„±")
    if 'cliff_df' in st.session_state and not st.session_state['cliff_df'].empty:
        cliff_df = st.session_state['cliff_df']

        # IUPAC ë§¤í•‘ ë° ì •ë ¬(í‘œì‹œìš©)
        base_df = st.session_state.get('df', pd.DataFrame())
        name_map = {}
        if len(base_df) > 0 and 'SMILES' in base_df.columns and 'iupac_name' in base_df.columns:
            tmp = base_df[['SMILES','iupac_name']].drop_duplicates()
            name_map = {str(r['SMILES']): (str(r['iupac_name']).strip() if str(r['iupac_name']).strip() else None) for _, r in tmp.iterrows()}
        def _name_or_smiles(s):
            s = str(s)
            n = name_map.get(s)
            return n if n and n.lower() != 'nan' else s
        disp = cliff_df.copy()
        disp['IUPAC_1'] = disp['SMILES_1'].map(_name_or_smiles)
        disp['IUPAC_2'] = disp['SMILES_2'].map(_name_or_smiles)
        sort_idx = disp.sort_values(by=['Activity_Diff','Similarity'], ascending=[False, False]).index.tolist()
        st.session_state['cliff_sorted_idx'] = sort_idx
        disp = disp.loc[sort_idx]
        cols = ['IUPAC_1','Activity_1','IUPAC_2','Activity_2','Similarity','Activity_Diff','SMILES_1','SMILES_2']
        cols = [c for c in cols if c in disp.columns]
        disp = disp[cols].reset_index(drop=True)
        disp.index = range(1, len(disp)+1)
        disp.index.name = 'Pair #'

        st.subheader("ë¶„ì„í•  Activity Cliff ìŒ ì„ íƒ")
        # í‘œì—ì„œ ì§ì ‘ ì²´í¬ë°•ìŠ¤ë¡œ ì„ íƒí•˜ë„ë¡ ì§€ì›
        try:
            # í‘œì‹œìš© í…Œì´ë¸”ì— ì„ íƒ ì»¬ëŸ¼ ì¶”ê°€
            disp_show = disp.copy()
            disp_show.insert(0, 'Pair #', list(range(1, len(disp_show)+1)))
            default_selected = set(st.session_state.get('selected_display_ids', []))
            disp_show.insert(0, 'ì„ íƒ', [ (i in default_selected) for i in disp_show['Pair #'] ])
            edited = st.data_editor(
                disp_show,
                hide_index=True,
                use_container_width=True,
                disabled=[c for c in disp_show.columns if c not in ['ì„ íƒ']],
                key='cliff_table_editor'
            )
            selected_display_ids = [ int(v) for v in edited[edited['ì„ íƒ'] == True]['Pair #'].tolist() ]
            st.session_state['selected_display_ids'] = selected_display_ids
        except Exception:
            # í´ë°±: ë©€í‹°ì…€ë ‰íŠ¸ ìœ ì§€
            st.dataframe(disp, use_container_width=True)
            options_1based = list(range(1, len(disp)+1))
            selected_display_ids = st.multiselect("ë¶„ì„ ë° ì‹œê°í™”í•  Pair ë²ˆí˜¸(1-based)ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options_1based)
        # 1-based â†’ ì›ë³¸ ì¸ë±ìŠ¤ ë§¤í•‘
        selected_indices = [ st.session_state['cliff_sorted_idx'][i-1] for i in selected_display_ids ]
        
        if selected_indices:
            # ì„ íƒ ìŒ ë¯¸ë¦¬ë³´ê¸°(ê°€ì„¤ ìƒì„± ì „ ì¦‰ì‹œ í‘œì‹œ)
            with st.container(border=True):
                max_preview = 6
                pairs = list(zip(selected_display_ids, selected_indices))
                if len(pairs) > max_preview:
                    st.info(f"ë¯¸ë¦¬ë³´ê¸°ëŠ” ìµœëŒ€ {max_preview}ìŒê¹Œì§€ë§Œ í‘œì‹œí•©ë‹ˆë‹¤. (ì´ ì„ íƒ {len(pairs)}ìŒ)")
                for disp_id, i in pairs[:max_preview]:
                    row = cliff_df.loc[i]
                    nm1 = name_map.get(str(row['SMILES_1'])) if name_map else None
                    nm2 = name_map.get(str(row['SMILES_2'])) if name_map else None
                    l1 = f"IUPAC: {nm1}" if nm1 else f"SMILES: {row['SMILES_1']}"
                    l2 = f"IUPAC: {nm2}" if nm2 else f"SMILES: {row['SMILES_2']}"
                    st.markdown(f"### ë¶„ì„ ìŒ #{disp_id}")
                    img = visualize_structure_difference(
                        smiles1=row['SMILES_1'],
                        smiles2=row['SMILES_2'],
                        legend1=f"{l1}\nActivity: {row['Activity_1']:.2f}",
                        legend2=f"{l2}\nActivity: {row['Activity_2']:.2f}"
                    )
                    st.image(img, caption=f"ìœ ì‚¬ë„: {row['Similarity']:.3f} | í™œì„±ë„ ì°¨ì´: {row['Activity_Diff']:.2f}")

            openai_api_key = get_openai_api_key_from_file()
            if not openai_api_key:
                st.warning("LLM ê°€ì„¤ ìƒì„±ì„ ìœ„í•´ openAI_key.txt íŒŒì¼ì— API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.session_state['openai_api_key'] = openai_api_key

                if st.button("ì„ íƒëœ ìŒì— ëŒ€í•œ ê°€ì„¤ ìƒì„±"):
                    output_dir = "hypotheses"
                    os.makedirs(output_dir, exist_ok=True)

                    for i in selected_indices:
                        row = cliff_df.loc[i]
                        st.subheader(f"ê°€ì„¤ ìƒì„± ì¤‘ Â· ìŒ #{i}")

                        with st.spinner(f"ìŒ #{i}ì— ëŒ€í•œ LLM ê°€ì„¤ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                            higher_is_better = st.session_state.get('activity_assumption') == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)'
                            
                            # ê°€ì •ì— ë”°ë¼ ê³ í™œì„±/ì €í™œì„± ë¶„ì ê²°ì •
                            if (higher_is_better and row['Activity_1'] > row['Activity_2']) or \
                               (not higher_is_better and row['Activity_1'] < row['Activity_2']):
                                high_act_smiles, high_act_val = row['SMILES_1'], row['Activity_1']
                                low_act_smiles, low_act_val = row['SMILES_2'], row['Activity_2']
                            else:
                                high_act_smiles, high_act_val = row['SMILES_2'], row['Activity_2']
                                low_act_smiles, low_act_val = row['SMILES_1'], row['Activity_1']

                            # ì»¨í…ìŠ¤íŠ¸ JSON êµ¬ì„±
                            try:
                                selected_axis = 'cell' if selected_view == 'ì„¸í¬ íŒ¨ë„ ë³´ê¸°' else 'target'
                                scale_used = 'pAct' if (st.session_state.get('activity_assumption') == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)') else 'raw'
                                ctx = build_pair_context(
                                    year=str(selected_year),
                                    pair_row=row,
                                    df_base=st.session_state['df'],
                                    data_root=data_root,
                                    selected_axis=selected_axis,
                                    scale_used=scale_used,
                                )
                            except Exception:
                                ctx = None

                            gen_result = generate_hypothesis(
                                api_key=openai_api_key,
                                smiles1=low_act_smiles,
                                activity1=low_act_val,
                                smiles2=high_act_smiles,
                                activity2=high_act_val,
                                structural_difference_description=f"í™”í•©ë¬¼ 1({low_act_smiles})ê³¼ í™”í•©ë¬¼ 2({high_act_smiles})ì˜ êµ¬ì¡°ì  ì°¨ì´ì .",
                                similarity=row['Similarity'],
                                context_json=ctx
                            )
                            _add_token_usage('generation', gen_result.get('model', 'unknown'), gen_result.get('usage', {}))
                            _show_last_and_total_tokens()
                            content = gen_result.get('content', '')

                            try:
                                hypothesis_data = json.loads(content)
                                display_md = format_hypothesis_for_markdown(hypothesis_data)
                                file_header = f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{low_act_smiles}` (í™œì„±ë„: {low_act_val:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{high_act_smiles}` (í™œì„±ë„: {high_act_val:.2f})\n\n---\n"
                                file_md = file_header + display_md
                                st.markdown(file_md, unsafe_allow_html=True)
                                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"hypothesis_pair_{i}_{timestamp}.md"
                                filepath = os.path.join(output_dir, filename)
                                save_hypothesis_to_md(file_md, filepath)
                                st.success(f"ê°€ì„¤ì´ '{filepath}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            except json.JSONDecodeError:
                                # LLM ì˜¤ë¥˜ ë©”ì‹œì§€ ì²˜ë¦¬
                                msg = str(content or "").strip()
                                rate_hit = ("rate" in msg.lower()) or ("429" in msg) or ("insufficient_quota" in msg) or ("quota" in msg.lower())
                                if rate_hit:
                                    st.error("LLM í˜¸ì¶œì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤(ë¦¬ë°‹/í•œë„). Billing/Usageë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                                else:
                                    st.error("LLM ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                                # ê°€ì„¤ ì €ì¥/í‘œì‹œëŠ” ìƒëµ(ìƒì„±í•˜ì§€ ì•ŠìŒ)
    else:
        st.info("2. Activity Cliff ë¶„ì„ íƒ­ì—ì„œ ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

with tab4:
    st.header("ğŸ“œ ì €ì¥ëœ ê°€ì„¤ ê´€ë¦¬ (ë³´ê¸°/ë‹¤ìš´ë¡œë“œ)")
    hypotheses_dir = "hypotheses"

    if st.button("ğŸ”„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("ì•„ì§ ì €ì¥ëœ ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        if not files:
            st.info("ì €ì¥ëœ ê°€ì„¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            selected_file = st.selectbox("í™•ì¸í•  ê°€ì„¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:", files)

            if selected_file:
                filepath = os.path.join(hypotheses_dir, selected_file)
                try:
                    with open(filepath, "r", encoding="utf-8") as file:
                        content = file.read()
                    
                    st.markdown("---")
                    st.subheader(f"ğŸ“„ {selected_file}")
                    st.markdown(content, unsafe_allow_html=True)

                    st.download_button(
                        label=f"'{selected_file}' ë‹¤ìš´ë¡œë“œ",
                        data=content,
                        file_name=selected_file,
                        mime="text/markdown"
                    )

                except Exception as e:
                    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

with tab5:
    st.header("ğŸ”„ ê°€ì„¤ í‰ê°€ ë° ìˆ˜ì •")
    hypotheses_dir = "hypotheses"

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("í‰ê°€í•  ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        hypothesis_files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        # --- 1. ê°€ì„¤ íŒŒì¼ ëª©ë¡ í‘œì‹œ ---
        st.subheader("ğŸ“‹ ê°€ì„¤ ëª©ë¡")
        selected_file = st.radio(
            "í‰ê°€í•  ê°€ì„¤ì„ ì„ íƒí•˜ì„¸ìš”:", 
            hypothesis_files, 
            key="selected_hypothesis_file",
            label_visibility="collapsed"
        )
        st.markdown("---")

        # --- 2. ì„ íƒëœ ê°€ì„¤ ë‚´ìš© ë° í‰ê°€/ìˆ˜ì • ---
        if selected_file:
            st.subheader(f"ğŸ“„ ì›ë³¸ ê°€ì„¤: {selected_file}")
            filepath = os.path.join(hypotheses_dir, selected_file)

            try:
                with open(filepath, "r", encoding="utf-8") as file:
                    content = file.read()
                
                parsed_data = parse_hypothesis_md(content)
                if not all(parsed_data.values()):
                    st.error(f"íŒŒì¼({selected_file})ì—ì„œ ë¶„ì ì •ë³´ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.stop()

                # ì›ë³¸ ê°€ì„¤ í‘œì‹œ
                st.markdown(content, unsafe_allow_html=True)
                st.markdown("---")

                # --- ê°€ì„¤ í‰ê°€ ---
                eval_container = st.container(border=True)
                with eval_container:
                    st.subheader("ğŸ”¬ ê°€ì„¤ í‰ê°€")
                    eval_key = f"eval_{selected_file}"
                    
                    if st.button("ê°€ì„¤ í‰ê°€ ì‹¤í–‰", key=f"eval_btn_{selected_file}"):
                        openai_api_key = get_openai_api_key_from_file()
                        if not openai_api_key:
                            st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                        else:
                            with st.spinner("LLMì´ ê°€ì„¤ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                                eval_response = evaluate_hypothesis(
                                    api_key=openai_api_key,
                                    hypothesis_text=parsed_data['hypothesis_body'],
                                    smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                    smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                    structural_difference_description=""
                                )
                                st.session_state[eval_key] = eval_response
                                # ìƒˆë¡œìš´ í‰ê°€ê°€ ì‹œì‘ë˜ë©´ ì´ì „ ìˆ˜ì • ê²°ê³¼ëŠ” ì‚­ì œ
                                if f"revise_{selected_file}" in st.session_state:
                                    del st.session_state[f"revise_{selected_file}"]
                    
                    if eval_key in st.session_state:
                        st.markdown("##### í‰ê°€ ê²°ê³¼")
                        try:
                            eval_data = json.loads(st.session_state[eval_key])
                            formatted_eval_md = format_evaluation_for_markdown(eval_data)
                            st.markdown(formatted_eval_md, unsafe_allow_html=True)

                            # í‰ê°€ ê²°ê³¼ ì €ì¥ ì„¹ì…˜
                            st.markdown("---")
                            evaluations_dir = "evaluations"
                            os.makedirs(evaluations_dir, exist_ok=True)
                            
                            base_filename = selected_file.replace(".md", "")
                            eval_filename = f"{base_filename}_Eval.md"
                            
                            content_to_save = f"# ì›ë³¸ ê°€ì„¤: {selected_file}\n\n{content}\n\n---\n\n# ê°€ì„¤ í‰ê°€ ê²°ê³¼\n\n{formatted_eval_md}"
                            eval_filepath = os.path.join(evaluations_dir, eval_filename)
                            save_hypothesis_to_md(content_to_save, eval_filepath)
                            st.success(f"í‰ê°€ ê²°ê³¼ê°€ '{eval_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.toast("í‰ê°€ ì €ì¥ ì™„ë£Œ!")

                        except json.JSONDecodeError:
                            st.error("LLM í‰ê°€ ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
                            st.text(st.session_state[eval_key])

                # --- ê°€ì„¤ ìˆ˜ì • ë° ì €ì¥ ---
                if eval_key in st.session_state:
                    revise_container = st.container(border=True)
                    with revise_container:
                        st.subheader("âœï¸ í‰ê°€ ê¸°ë°˜ ê°€ì„¤ ìˆ˜ì •")
                        revise_key = f"revise_{selected_file}"

                        if st.button("í‰ê°€ ê¸°ë°˜ìœ¼ë¡œ ê°€ì„¤ ìˆ˜ì •", key=f"revise_btn_{selected_file}"):
                            openai_api_key = get_openai_api_key_from_file()
                            if not openai_api_key:
                                st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                            else:
                                with st.spinner("LLMì´ ê°€ì„¤ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                                    revise_response = revise_hypothesis(
                                        api_key=openai_api_key,
                                        original_hypothesis_text=parsed_data['hypothesis_body'],
                                        review_findings=st.session_state[eval_key],
                                        smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                        smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                        structural_difference_description=""
                                    )
                                    st.session_state[revise_key] = revise_response
                        
                        if revise_key in st.session_state:
                            st.markdown("##### ìˆ˜ì •ëœ ê°€ì„¤")
                            try:
                                revised_data = json.loads(st.session_state[revise_key])
                                display_md = format_hypothesis_for_markdown(revised_data)
                                st.markdown(display_md, unsafe_allow_html=True)

                                # ìˆ˜ì •ëœ ê°€ì„¤ ì €ì¥ ì„¹ì…˜
                                st.markdown("---")
                                st.subheader("ğŸ’¾ ìˆ˜ì •ëœ ê°€ì„¤ ì €ì¥")
                                
                                file_header = f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{parsed_data['smiles1']}` (í™œì„±ë„: {parsed_data['activity1']:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{parsed_data['smiles2']}` (í™œì„±ë„: {parsed_data['activity2']:.2f})\n\n---"
                                final_md_to_save = file_header + display_md

                                new_filename = f"revised_{selected_file}"
                                new_filepath = os.path.join(hypotheses_dir, new_filename)
                                save_hypothesis_to_md(final_md_to_save, new_filepath)
                                st.success(f"ìˆ˜ì •ëœ ê°€ì„¤ì´ '{new_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.toast("ì €ì¥ ì™„ë£Œ!")

                            except json.JSONDecodeError:
                                st.error("LLM ìˆ˜ì • ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
                                st.text(st.session_state[revise_key])

            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

with tab6:
    st.header("ğŸ¤– ìë™ ê°€ì„¤ ìˆ˜ì •")
    hypotheses_dir = "hypotheses"

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("ìë™ ìˆ˜ì •í•  ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        hypothesis_files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        selected_file_auto = st.selectbox(
            "ìë™ ìˆ˜ì •ì„ ì‹œì‘í•  ê°€ì„¤ì„ ì„ íƒí•˜ì„¸ìš”:", 
            hypothesis_files, 
            key="selected_hypothesis_file_auto"
        )
        
        col1, col2 = st.columns(2)
        with col1:
            min_iterations = st.number_input("ìµœì†Œ ë°˜ë³µ íšŸìˆ˜:", min_value=1, max_value=10, value=1, step=1)
        with col2:
            max_iterations = st.number_input("ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜:", min_value=1, max_value=10, value=3, step=1)

        if st.button("ğŸ¤– ìë™ ìˆ˜ì • ì‹œì‘", key="auto_revise_start"):
            openai_api_key = get_openai_api_key_from_file()
            if not openai_api_key:
                st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                st.stop()

            filepath = os.path.join(hypotheses_dir, selected_file_auto)
            try:
                with open(filepath, "r", encoding="utf-8") as file:
                    content = file.read()
                
                parsed_data = parse_hypothesis_md(content)
                if not all(parsed_data.values()):
                    st.error(f"íŒŒì¼({selected_file_auto})ì—ì„œ ë¶„ì ì •ë³´ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.stop()

            except Exception as e:
                st.error(f"ì›ë³¸ ê°€ì„¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.stop()

            current_hypothesis_body = parsed_data['hypothesis_body']
            final_hypothesis_body = ""

            with st.status(f"'{selected_file_auto}'ì— ëŒ€í•œ ìë™ ìˆ˜ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...", expanded=True) as status:
                for i in range(max_iterations):
                    st.write(f"---")
                    st.write(f"**ğŸš€ ë°˜ë³µ {i+1}/{max_iterations}**")
                    
                    # 1. í‰ê°€
                    st.write("1ï¸âƒ£ ê°€ì„¤ì„ í‰ê°€í•©ë‹ˆë‹¤...")
                    try:
                        eval_response = evaluate_hypothesis(
                            api_key=openai_api_key,
                            hypothesis_text=current_hypothesis_body,
                            smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                            smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                            structural_difference_description=""
                        )
                        eval_data = json.loads(eval_response)
                        verdict = eval_data.get('summary', {}).get('verdict', 'Unknown').upper()
                        
                        with st.expander("í‰ê°€ ê²°ê³¼ ë³´ê¸°"):
                            st.markdown(format_evaluation_for_markdown(eval_data), unsafe_allow_html=True)

                    except Exception as e:
                        st.error(f"ë°˜ë³µ {i+1}ì—ì„œ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        status.update(label="ì˜¤ë¥˜ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨", state="error")
                        st.stop()

                    # 2. íŒì •ì— ë”°ë¥¸ ë¶„ê¸°
                    st.write(f"2ï¸âƒ£ í‰ê°€ íŒì •: **{verdict}**")
                    if ("GOOD" in verdict or "SOUND" in verdict) and (i + 1) >= min_iterations:
                        st.success(f"âœ… ê°€ì„¤ì´ 'Good' ë˜ëŠ” 'Unsound'ë¡œ íŒì •ë˜ê³  ìµœì†Œ ë°˜ë³µ íšŸìˆ˜({min_iterations})ì— ë„ë‹¬í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        final_hypothesis_body = current_hypothesis_body
                        status.update(label="ìë™ ìˆ˜ì • ì™„ë£Œ!", state="complete")
                        break
                    
                    elif "WEAK" in verdict:
                        st.info("ğŸ¤” ê°€ì„¤ì´ 'Weak'ë¡œ íŒì •ë˜ì–´ ìˆ˜ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                        # 3. ìˆ˜ì •
                        st.write("3ï¸âƒ£ í‰ê°€ ê¸°ë°˜ìœ¼ë¡œ ê°€ì„¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤...")
                        try:
                            revise_response = revise_hypothesis(
                                api_key=openai_api_key,
                                original_hypothesis_text=current_hypothesis_body,
                                review_findings=eval_response,
                                smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                structural_difference_description=""
                            )
                            revised_data = json.loads(revise_response)
                            current_hypothesis_body = format_hypothesis_for_markdown(revised_data)
                            
                            with st.expander("ìˆ˜ì •ëœ ê°€ì„¤ ë‚´ìš© ë³´ê¸°"):
                                st.markdown(current_hypothesis_body, unsafe_allow_html=True)

                        except Exception as e:
                            st.error(f"ë°˜ë³µ {i+1}ì—ì„œ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            status.update(label="ì˜¤ë¥˜ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨", state="error")
                            st.stop()
                    else:
                        st.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íŒì •('{verdict}')ìœ¼ë¡œ ì¸í•´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        final_hypothesis_body = current_hypothesis_body
                        status.update(label="ì•Œ ìˆ˜ ì—†ëŠ” íŒì •ìœ¼ë¡œ ì¤‘ë‹¨ë¨", state="error")
                        break
                
                else: # for-else loop: break ì—†ì´ ëë‚¬ì„ ê²½ìš°
                    st.warning(f"ğŸ”” ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                    final_hypothesis_body = current_hypothesis_body
                    status.update(label="ìµœëŒ€ ë°˜ë³µ í›„ ì™„ë£Œ", state="complete")

            # ìµœì¢… ê²°ê³¼ ì €ì¥
            if final_hypothesis_body:
                st.markdown("---")
                st.subheader("ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥")
                
                file_header = f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{parsed_data['smiles1']}` (í™œì„±ë„: {parsed_data['activity1']:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{parsed_data['smiles2']}` (í™œì„±ë„: {parsed_data['activity2']:.2f})\n\n---"
                final_md_to_save = file_header + final_hypothesis_body

                # ìƒˆ íŒŒì¼ëª… ìƒì„±
                base_name = selected_file_auto.replace('.md', '')
                if base_name.startswith('auto_'): # ê¸°ì¡´ ì ‘ë‘ì‚¬ ì œê±°
                    base_name = base_name[5:]
                
                new_filename = f"auto_{base_name}.md"
                new_filepath = os.path.join(hypotheses_dir, new_filename)
                
                save_hypothesis_to_md(final_md_to_save, new_filepath)
                st.success(f"ìµœì¢… ìˆ˜ì •ëœ ê°€ì„¤ì´ '{new_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                st.markdown("##### ìµœì¢… ê°€ì„¤ ë‚´ìš©:")
                st.markdown(final_md_to_save, unsafe_allow_html=True)
