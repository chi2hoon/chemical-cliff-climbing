import streamlit as st
import pandas as pd
import datetime
import os
import json
import zipfile
import io
from modules.cheminformatics import find_activity_cliffs
from modules.visualization import visualize_structure_difference, smiles_to_image_b64
from modules.llm_handler import generate_hypothesis, evaluate_hypothesis, revise_hypothesis, create_activity_summary
from modules.io_utils import (
    load_smiles_activity_csv,
    save_hypothesis_to_md,
    parse_hypothesis_md,
    load_hoon_gold_data,
    load_hoon_ac_pairs,
    get_available_gold_years,
    get_available_panel_ids,
    get_all_available_panels_and_years,
    get_cell_lines_for_panel
)

# --- Helper Functions ---

def get_openai_api_key_from_file():
    for path in ["openAI_key.txt", "base/openAI_key.txt"]:
        try:
            with open(path, "r") as f:
                key = f.read().strip()
                if key:
                    return key
        except FileNotFoundError:
            continue
    return None


def _init_token_usage_state():
    if 'token_usage' not in st.session_state:
        st.session_state['token_usage'] = {
            'calls': [],
            'totals': {
                'prompt_tokens': 0,
                'completion_tokens': 0,
                'total_tokens': 0,
            }
        }


def _reset_token_usage():
    st.session_state['token_usage'] = {
        'calls': [],
        'totals': {
            'prompt_tokens': 0,
            'completion_tokens': 0,
            'total_tokens': 0,
        }
    }


def _add_token_usage(phase: str, model: str, usage: dict):
    """Accumulate token usage in session state.

    phase: one of 'generation' | 'evaluation' | 'revision'
    usage: dict with keys prompt_tokens, completion_tokens, total_tokens
    """
    _init_token_usage_state()
    usage = usage or {}
    pt = int(usage.get('prompt_tokens', 0) or 0)
    ct = int(usage.get('completion_tokens', 0) or 0)
    tt = int(usage.get('total_tokens', pt + ct) or (pt + ct))

    st.session_state['token_usage']['calls'].append({
        'phase': phase,
        'model': model,
        'prompt_tokens': pt,
        'completion_tokens': ct,
        'total_tokens': tt,
    })
    st.session_state['token_usage']['totals']['prompt_tokens'] += pt
    st.session_state['token_usage']['totals']['completion_tokens'] += ct
    st.session_state['token_usage']['totals']['total_tokens'] += tt


def _show_last_and_total_tokens():
    tu = st.session_state.get('token_usage')
    if not tu or not tu.get('calls'):
        return
    last = tu['calls'][-1]
    totals = tu['totals']
    st.info(
        f"í† í° ì‚¬ìš©ëŸ‰ â€” ì´ë²ˆ í˜¸ì¶œ({last['phase']}, {last['model']}): "
        f"prompt {last['prompt_tokens']}, completion {last['completion_tokens']}, total {last['total_tokens']} | "
        f"ëˆ„ì : prompt {totals['prompt_tokens']}, completion {totals['completion_tokens']}, total {totals['total_tokens']}"
    )

def format_hypothesis_for_markdown(data: dict) -> str:
    """ì£¼ì–´ì§„ ê°€ì„¤ ë°ì´í„°(dict)ë¥¼ ê°€ë…ì„± ì¢‹ì€ ë§ˆí¬ë‹¤ìš´ ë° HTML ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    md_lines = []

    # ê¸°ë³¸ ì •ë³´
    md_lines.append(f"### ğŸ† ì£¼ìš” ê°€ì„¤: {data.get('primary_hypothesis', 'N/A')}")
    md_lines.append(f"- **ë” í™œì„±ì´ ë†’ì€ í™”í•©ë¬¼:** `{data.get('more_active', 'N/A')}`")
    md_lines.append(f"- **í™œì„±ë„ ë³€í™” ì„¤ëª…:** {data.get('delta_pAct_explained', 'N/A')}")
    md_lines.append(f"- **ì‹ ë¢°ë„:** {data.get('confidence', 0.0) * 100:.1f}%")
    md_lines.append("\n")

    # ê¸°ì „ ë¶„ì„
    md_lines.append("### ğŸ”¬ ê¸°ì „ ë¶„ì„")
    rationale = data.get('mechanistic_rationale', {})
    for key, value in rationale.items():
        if value and value not in ["N/A", "ì„ íƒ"]:
            md_lines.append(f"- **{key.replace('_', ' ').title()}:** {value}")
    md_lines.append("\n")

    # ì„¤ê³„ ì œì•ˆ (HTML í…Œì´ë¸”ë¡œ ë³€ê²½)
    md_lines.append("### ğŸ’¡ ê²€ì¦ì„ ìœ„í•œ ë¶„ì ì„¤ê³„ ì œì•ˆ")
    suggestions = data.get('design_suggestions', [])
    if suggestions:
        html_table = "<table><thead><tr><th>Design (SMILES)</th><th>Structure</th><th>Expected Effect</th><th>Rationale</th><th>Validation Metric</th></tr></thead><tbody>"
        for s in suggestions:
            smiles = s.get('design', '')
            b64_img = smiles_to_image_b64(smiles) if smiles else ''
            img_tag = f'<img src="data:image/png;base64,{b64_img}" width="200">' if b64_img else ''
            
            html_table += f"<tr>"
            html_table += f"<td>`{smiles}`</td>"
            html_table += f"<td>{img_tag}</td>"
            html_table += f"<td>{s.get('expected_effect', 'N/A')}</td>"
            html_table += f"<td>{s.get('rationale', 'N/A')}</td>"
            html_table += f"<td>{s.get('validation_metric', 'N/A')}</td>"
            html_table += "</tr>"
        html_table += "</tbody></table>"
        md_lines.append(html_table)
    md_lines.append("\n")

    # ë°˜ëŒ€ ê°€ì„¤
    md_lines.append("### ğŸ¤” ë°˜ëŒ€ ê°€ì„¤")
    counter_hypotheses = data.get('counter_hypotheses', [])
    for i, counter in enumerate(counter_hypotheses, 1):
        md_lines.append(f"{i}. {counter}")
    md_lines.append("\n")

    # ADMET ìœ„í—˜ì„±
    md_lines.append("### âš ï¸ ADMET ìœ„í—˜ì„± ì˜ˆì¸¡")
    admet_flags = data.get('admet_flags', [])
    for flag in admet_flags:
        md_lines.append(f"- {flag}")
    md_lines.append("\n")
    
    # ê°€ì • ë° í•œê³„
    md_lines.append("### ğŸ“‹ ê°€ì • ë° í•œê³„")
    assumptions = data.get('assumptions_and_limits', [])
    for assumption in assumptions:
        md_lines.append(f"- {assumption}")

    return "\n".join(md_lines)

def display_cliff_results_with_images(cliff_df):
    """Iterates through cliff dataframe and displays each pair with a selection button."""
    st.write(f"ì´ {len(cliff_df)}ê°œì˜ Activity Cliff ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ê° í•­ëª©ì„ í™•ì¸í•˜ê³  ê°€ì„¤ì„ ìƒì„±í•  ìŒì„ ì„ íƒí•˜ì„¸ìš”.")

    for index, row in cliff_df.iterrows():
        # Check if this row is the selected one
        is_selected = ('selected_cliff_index' in st.session_state and st.session_state['selected_cliff_index'] == index)
        
        with st.expander(f"ë¶„ì„ ìŒ #{index} (ìœ ì‚¬ë„: {row['Similarity']:.3f}, í™œì„±ë„ ì°¨ì´: {row['Activity_Diff']:.2f})", expanded=is_selected):
            
            smiles1 = row['SMILES_1']
            activity1 = row['Activity_1']
            smiles2 = row['SMILES_2']
            activity2 = row['Activity_2']

            legend1 = f"Mol 1 (Activity: {activity1:.2f})"
            legend2 = f"Mol 2 (Activity: {activity2:.2f})"

            try:
                img = visualize_structure_difference(smiles1, smiles2, legend1, legend2)
                st.image(img, use_container_width=True)

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**í™”í•©ë¬¼ 1 (Molecule 1)**")
                    st.code(smiles1, language='smiles')
                with col2:
                    st.markdown("**í™”í•©ë¬¼ 2 (Molecule 2)**")
                    st.code(smiles2, language='smiles')
                
                st.markdown("---")
                # Add selection button
                if st.button(f"ì„ íƒí•˜ê¸°", key=f"select_{index}", type="primary" if not is_selected else "secondary"):
                    # Save selected index and pair details for use in Tab 3
                    st.session_state['selected_cliff_index'] = index
                    st.session_state['selected_cliff_pair'] = {
                        'index': int(index),
                        'SMILES_1': smiles1,
                        'Activity_1': float(activity1) if activity1 is not None else None,
                        'SMILES_2': smiles2,
                        'Activity_2': float(activity2) if activity2 is not None else None,
                        'Similarity': float(row.get('Similarity')) if 'Similarity' in row else None,
                        'Activity_Diff': float(row.get('Activity_Diff')) if 'Activity_Diff' in row else None,
                    }
                    st.rerun()

            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ìŒ #{index}): {e}")

    # Show a message if a pair is selected
    if 'selected_cliff_index' in st.session_state:
        st.success(f"ë¶„ì„ ìŒ #{st.session_state['selected_cliff_index']}ì´(ê°€) ê°€ì„¤ ìƒì„±ì„ ìœ„í•´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. 3ë²ˆ íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ê°€ì„¤ ìƒì„±ì„ ê³„ì†í•˜ì„¸ìš”.")

def format_evaluation_for_markdown(data: dict) -> str:
    """Evaluation ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    md_lines = []
    summary = data.get('summary', {})
    md_lines.append(f"### ğŸ“ í‰ê°€ ìš”ì•½")
    md_lines.append(f"- **íŒì •:** {summary.get('verdict', 'N/A')}")
    md_lines.append(f"- **ì‹¬ì‚¬ ë°©ë²•:** {summary.get('method_sketch', 'N/A')}")
    md_lines.append("\n")

    details = data.get('detailed_solution', {})
    md_lines.append("### ğŸ” ìƒì„¸ í‰ê°€")
    md_lines.append(f"- **ê¸°ë³¸ ì¼ì¹˜ì„±:** {details.get('consistency_check', 'N/A')}")
    md_lines.append(f"- **ê´€ì ë³„ ê²€ì¦:** {details.get('aspect_validation', 'N/A')}")
    md_lines.append(f"- **ë°˜ëŒ€ ê°€ì„¤ ê²€í† :** {details.get('counter_hypothesis_review', 'N/A')}")
    md_lines.append(f"- **ì„¤ê³„ ì œì•ˆ ê²€í† :** {details.get('design_suggestion_review', 'N/A')}")
    md_lines.append(f"- **ì¶”ê°€ í•„ìš” ìš”ì†Œ:** {details.get('additional_requirements', 'N/A')}")
    return "\n".join(md_lines)

# --- Streamlit App ---

st.set_page_config(layout="centered")
st.title("ğŸ”¬ SAR ë¶„ì„ ë° ê°€ì„¤ ìƒì„±/í‰ê°€/ìˆ˜ì • ìë™í™” ë„êµ¬")
st.write("ë¶„ì êµ¬ì¡°ì™€ í™œì„± ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì¡°-í™œì„± ê´€ê³„(SAR) ë¶„ì„ ë° ê°€ì„¤ ìƒì„±, í‰ê°€, ìˆ˜ì •ì„ ìë™í™”í•©ë‹ˆë‹¤.")


tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "1. ë°ì´í„°ì…‹ ì„ íƒ",
    "2. Activity Cliff ë¶„ì„",
    "3. ê°€ì„¤ ìƒì„±",
    "4. ê°€ì„¤ ê´€ë¦¬",
    "5. ê°€ì„¤ í‰ê°€ ë° ìˆ˜ì •",
    "6. ìë™ ê°€ì„¤ ìˆ˜ì •"
])

with tab1:
    st.header("1. Gold ë°ì´í„° ë¡œë“œ")
    st.markdown("í‘œì¤€í™”ëœ gold ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

    # ë°ì´í„°ì…‹ ì„ íƒ
    data_root = "base/data"
    panel_years_map = get_all_available_panels_and_years(data_root)
    available_years_all = get_available_gold_years(data_root)

    if not available_years_all:
        st.warning("Gold ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. hoon íŒŒì´í”„ë¼ì¸ì—ì„œ `gold` ìŠ¤í…Œì´ì§€ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        # íŒ¨ë„ ì´ë¦„ ë§¤í•‘
        panel_names_map = {
            "blca": "ë°©ê´‘ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "prad": "ì „ë¦½ì„ ì•”ì„¸í¬ì£¼ íŒ¨ë„", 
            "luad": "íì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "brca": "ìœ ë°©ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "heme": "í˜ˆì•¡ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "paad": "ì·Œì¥ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "coad": "ëŒ€ì¥ì•”ì„¸í¬ì£¼ íŒ¨ë„",
            "misc12": "ë‡Œì•”/ê¸°íƒ€ íŒ¨ë„",
            "misc13": "ê¸°íƒ€ íŒ¨ë„"
        }

        # ë…„ë„(ì™¼ìª½) - íŒ¨ë„(ì˜¤ë¥¸ìª½, ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ)
        col_year, col_panel = st.columns([1, 2])

        with col_year:
            selected_year = st.selectbox("ğŸ“… ë°ì´í„°ì…‹ ë…„ë„", sorted(available_years_all), index=0)

        selected_panel = None
        with col_panel:
            if panel_years_map:
                # ì„ íƒëœ ë…„ë„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íŒ¨ë„ë§Œ í‘œì‹œ
                panel_options = panel_years_map.keys()
                filtered_panel_ids = [pid for pid in panel_options if selected_year in panel_years_map[pid]]
                panel_display_options = ["ì „ì²´ íŒ¨ë„"]
                panel_id_to_display = {"ì „ì²´ íŒ¨ë„": None}
                for panel_id in sorted(filtered_panel_ids):
                    display_name = panel_names_map.get(panel_id, panel_id)
                    display_option = f"{panel_id} ({display_name})"
                    panel_display_options.append(display_option)
                    panel_id_to_display[display_option] = panel_id
                selected_panel_display = st.selectbox("ğŸ§¬ íŒ¨ë„ ì„ íƒ", panel_display_options, index=0)
                selected_panel = panel_id_to_display[selected_panel_display]

        # ì„¸í¬ì£¼ ì…€ë ‰í„° (íŒ¨ë„ ì„ íƒ ì‹œ)
        selected_cell_line = None
        if selected_panel:
            cell_lines = get_cell_lines_for_panel(selected_year, selected_panel, data_root)
            if cell_lines:
                selected_cell_line = st.selectbox("ğŸ§« ì„¸í¬ì£¼ ì„ íƒ", ["ì „ì²´ ì„¸í¬ì£¼"] + cell_lines, index=0)
                if selected_cell_line == "ì „ì²´ ì„¸í¬ì£¼":
                    selected_cell_line = None

        # ë¡œë“œ ë²„íŠ¼ - selected_yearê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ
        if selected_year:
            st.markdown("### ğŸš€ Gold ë°ì´í„° ë¡œë“œ")
            load_text = f"{selected_year}ë…„ Gold ë°ì´í„° ë¡œë“œ"
            if selected_panel:
                panel_name = panel_names_map.get(selected_panel, selected_panel)
                load_text += f" ({panel_name})"

            if st.button(f"ğŸ“Š {load_text}", type="primary", use_container_width=True):
                try:
                    with st.spinner(f"{selected_year}ë…„ Gold ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                        df_gold = load_hoon_gold_data(
                            year=selected_year, 
                            data_root=data_root, 
                            panel_id=selected_panel,
                            cell_line=selected_cell_line
                        )

                        if df_gold.empty:
                            if selected_panel:
                                st.error(f"{selected_year}ë…„ {selected_panel} íŒ¨ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.error(f"{selected_year}ë…„ Gold ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.session_state['df'] = df_gold
                            st.session_state['auto_suggestion'] = {"smiles_col": "SMILES", "activity_col": "Activity"}
                            
                            success_msg = f"{selected_year}ë…„ Gold ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ {len(df_gold)}ê°œ ë ˆì½”ë“œ"
                            if selected_panel:
                                success_msg += f" ({panel_names_map.get(selected_panel, selected_panel)})"
                            
                            st.success(success_msg)
                            st.dataframe(df_gold.head())

                            # Gold ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ë³´ í‘œì‹œ
                            st.info("""**Gold ë°ì´í„° ìŠ¤í‚¤ë§ˆ:**
â€¢ SMILES: í‘œì¤€í™”ëœ ìºë…¸ë‹ˆì»¬ SMILES
â€¢ Activity: í‘œì¤€í™”ëœ í™œì„±ë„ ê°’ (value_std)
â€¢ ë©”íƒ€ë°ì´í„°: assay_id, target_id, unit_std ë“±""")

                except Exception as e:
                    st.error(f"Gold ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

    # Gold ë°ì´í„° ì„¤ëª…
    with st.expander("ğŸ“‹ Gold ë°ì´í„° ì„¤ëª…"):
        st.markdown("""
        **Gold ë°ì´í„°ì…‹ íŠ¹ì§•:**
        - **í‘œì¤€í™”ëœ êµ¬ì¡°**: `smiles_canonical` (RDKit ìºë…¸ë‹ˆì»¬ SMILES)
        - **í‘œì¤€í™”ëœ í™œì„±ë„**: `value_std` (ë‹¨ìœ„ ì •ê·œí™”ëœ ìˆ˜ì¹˜)
        - **í’ˆì§ˆ ë³´ì¥**: ë¹ˆ ê°’ ë° ìœ íš¨í•˜ì§€ ì•Šì€ SMILES í•„í„°ë§
        - **ë©”íƒ€ë°ì´í„°**: assay_id, target_id, unit_std ë“± ë¶„ì„ì— ìœ ìš©í•œ ì •ë³´ í¬í•¨
        - **íŒ¨ë„ ê¸°ë°˜**: (2017 ë°ì´í„°ëŠ” íŒ¨ë„/cell_line ì—´ì´ í¬í•¨ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)

        **í™œìš© íŒ:**
        - base ì•±ì—ì„œ ìœ ì‚¬ë„/í™œì„±ë„ì°¨ ê³„ì‚° ì‹œ `smiles_col=SMILES`, `activity_col=Activity`ë¡œ ì„¤ì •
        - ë™ì¼ íŒ¨ë„ ë‚´ì—ì„œ ë¹„êµí•˜ë©´ ë” ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        
        **í˜„ì¬ ê°€ìš© ë°ì´í„°:**
        - **2017ë…„**: 2017 Gold ì‚°ì¶œì„ ìš°ì„  ì§€ì›í•©ë‹ˆë‹¤.
        - **2018/2020/2021ë…„**: ì¶”í›„ í†µí•© ì˜ˆì •
        """)

    st.markdown("---")
    with st.expander("ğŸ› ï¸ íŒŒì´í”„ë¼ì¸ ì •ë³´"):
        st.markdown("""
        **ë°ì´í„° íŒŒì´í”„ë¼ì¸:**
        ```
        Raw Excel â†’ Bronze â†’ Silver â†’ Gold â†’ Activity Cliff
        ```
        - **Bronze**: ì›ì²œ ë°ì´í„° ìˆ˜ì§‘/ê²€ì¦
        - **Silver**: ë‹¨ìœ„ í‘œì¤€í™” (`value_std`, `unit_std`, censor ìœ ì§€)
        - **Gold**: ë¶„ì„ ì¹œí™” í…Œì´ë¸” (SMILES + Activity + ë©”íƒ€ë°ì´í„°)
        - **AC**: Activity Cliff ì‚¬ì „ ê³„ì‚°

        **Gold ìƒì„± ëª…ë ¹ì–´:**
        ```bash
        python hoon/udm_cli.py silver --config hoon/configs/2017.yml --root hoon/data
        python hoon/udm_cli.py smiles --config hoon/configs/2017.yml --root hoon/data  
        python hoon/udm_cli.py gold --config hoon/configs/2017.yml --root hoon/data
        ```
        """)

with tab2:
    st.header("2. Activity Cliff ë¶„ì„")
    st.markdown("ì‚¬ì „ ê³„ì‚°ëœ Activity Cliff(AC) ìŒì„ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜, 1ë²ˆ íƒ­ì—ì„œ ë¡œë“œí•œ Gold ë°ì´í„°ì…‹ìœ¼ë¡œ ì§ì ‘ ACë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")
    
    # --- ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ ë° ë¶„ì„ ì‹¤í–‰ ---
    source = st.radio("ë°ì´í„° ì†ŒìŠ¤", ["Gold ë°ì´í„°ë¡œ ì§ì ‘ ê³„ì‚°", "ì‚¬ì „ê³„ì‚°ëœ AC ìŒ ë¶ˆëŸ¬ì˜¤ê¸°"], index=0, horizontal=True, key="ac_source")

    if source == "ì‚¬ì „ê³„ì‚°ëœ AC ìŒ ë¶ˆëŸ¬ì˜¤ê¸°":
        if st.button("Hoon ì‚¬ì „ê³„ì‚° AC ìŒ ë¡œë“œ"):
            try:
                with st.spinner("ì‚¬ì „ê³„ì‚°ëœ Activity Cliff ìŒì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    cliff_df = load_hoon_ac_pairs(data_root="base/data")
                if cliff_df is None or cliff_df.empty:
                    st.warning("ì‚¬ì „ê³„ì‚°ëœ AC ìŒì´ ì—†ìŠµë‹ˆë‹¤. `hoon` íŒŒì´í”„ë¼ì¸ì—ì„œ `ac` ë˜ëŠ” `ac-all` ìŠ¤í…Œì´ì§€ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                    if 'cliff_df' in st.session_state:
                        del st.session_state['cliff_df'] # Clear previous results
                else:
                    st.session_state['cliff_df'] = cliff_df
                    st.success(f"{len(cliff_df)}ê°œì˜ ì‚¬ì „ê³„ì‚°ëœ Activity Cliff ìŒì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"AC ìŒ ë¡œë“œ ì‹¤íŒ¨: {e}")

    elif source == "Gold ë°ì´í„°ë¡œ ì§ì ‘ ê³„ì‚°":
        if 'df' not in st.session_state or st.session_state['df'].empty:
            st.info("ë¨¼ì € 1ë²ˆ íƒ­ì—ì„œ ë¶„ì„í•  Gold ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            df = st.session_state['df']
            with st.container(border=True):
                st.subheader("ê³„ì‚° íŒŒë¼ë¯¸í„° ì„¤ì •")
                col1, col2 = st.columns(2)
                with col1:
                    auto = st.session_state.get('auto_suggestion', {})
                    smiles_col_default = auto.get('smiles_col') if auto.get('smiles_col') in df.columns else None
                    activity_col_default = auto.get('activity_col') if auto.get('activity_col') in df.columns else None

                    smiles_col = st.selectbox("SMILES ì»¬ëŸ¼:", df.columns, index=(list(df.columns).index(smiles_col_default) if smiles_col_default else 0))
                    activity_col = st.selectbox("í™œì„±ë„ ì»¬ëŸ¼:", df.columns, index=(list(df.columns).index(activity_col_default) if activity_col_default else (1 if len(df.columns) > 1 else 0)))

                with col2:
                    similarity_threshold = st.slider("êµ¬ì¡° ìœ ì‚¬ë„ ì„ê³„ê°’ (Tanimoto)", 0.7, 1.0, 0.85, 0.01)
                    activity_diff_threshold = st.number_input("í™œì„±ë„ ì°¨ì´ ì„ê³„ê°’", min_value=0.0, value=1.0, step=0.1)

                activity_assumption = st.radio(
                    "í™œì„±ë„ ë°ì´í„°ì˜ ì˜ë¯¸:",
                    ('ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)', 'ê°’ì´ ë‚®ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Lower is better)'),
                    key='activity_assumption'
                )

                if st.button("Activity Cliff ë¶„ì„ ì‹¤í–‰", type="primary"):
                    with st.spinner("Activity Cliffë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        work_df = df.copy()
                        work_df = work_df.dropna(subset=[activity_col])
                        work_df = work_df.reset_index(drop=True)
                        
                        cliff_df = find_activity_cliffs(
                            work_df,
                            smiles_col=smiles_col,
                            activity_col=activity_col,
                            similarity_threshold=similarity_threshold,
                            activity_diff_threshold=activity_diff_threshold,
                            higher_is_better=(activity_assumption == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)')
                        )
                    
                    st.session_state['cliff_df'] = cliff_df
                    st.success(f"ë¶„ì„ ì™„ë£Œ! ì´ {len(cliff_df)}ê°œì˜ Activity Cliff ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    
                    # í™œì„±ë„ ì§€í‘œì— ëŒ€í•œ ìš”ì•½ ì •ë³´ í‘œì‹œ
                    summary_text = create_activity_summary(activity_col, (activity_assumption == 'ê°’ì´ ë†’ì„ìˆ˜ë¡ í™œì„±ë„ê°€ ë†’ìŒ (Higher is better)'))
                    st.markdown("---")
                    st.markdown(summary_text)

    # --- ê²°ê³¼ í‘œì‹œ ì˜ì—­ ---
    if 'cliff_df' in st.session_state and not st.session_state['cliff_df'].empty:
        st.markdown("---")
        st.subheader("ğŸ“Š Activity Cliff ë¶„ì„ ê²°ê³¼")
        
        cliff_df = st.session_state['cliff_df']

        # --- ì •ë ¬ UI ---
        sort_option = st.selectbox(
            "ê²°ê³¼ ì •ë ¬ ê¸°ì¤€:",
            [
                "ê¸°ë³¸ (ì¸ë±ìŠ¤)",
                "ìœ ì‚¬ë„ (ë†’ì€ ìˆœ)",
                "ìœ ì‚¬ë„ (ë‚®ì€ ìˆœ)",
                "í™œì„±ë„ ì°¨ì´ (í° ìˆœ)",
                "í™œì„±ë„ ì°¨ì´ (ì‘ì€ ìˆœ)",
            ]
        )

        # --- ì •ë ¬ ë¡œì§ ---
        sorted_df = cliff_df
        if sort_option == "ìœ ì‚¬ë„ (ë†’ì€ ìˆœ)":
            sorted_df = cliff_df.sort_values(by="Similarity", ascending=False)
        elif sort_option == "ìœ ì‚¬ë„ (ë‚®ì€ ìˆœ)":
            sorted_df = cliff_df.sort_values(by="Similarity", ascending=True)
        elif sort_option == "í™œì„±ë„ ì°¨ì´ (í° ìˆœ)":
            sorted_df = cliff_df.sort_values(by="Activity_Diff", ascending=False)
        elif sort_option == "í™œì„±ë„ ì°¨ì´ (ì‘ì€ ìˆœ)":
            sorted_df = cliff_df.sort_values(by="Activity_Diff", ascending=True)
        
        # --- ê²°ê³¼ í‘œì‹œ ---
        display_cliff_results_with_images(sorted_df.reset_index(drop=True))

with tab3:
    st.header("3. ê°€ì„¤ ìƒì„±")

    # ì„ íƒëœ ìŒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    pair = st.session_state.get('selected_cliff_pair')

    # í˜¸í™˜ì„±: ì˜ˆì „ ìƒíƒœì—ì„œëŠ” indexë§Œ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, cliff_dfì—ì„œ ë³µì› ì‹œë„
    if not pair and ('selected_cliff_index' in st.session_state) and ('cliff_df' in st.session_state):
        try:
            idx = st.session_state['selected_cliff_index']
            row = st.session_state['cliff_df'].iloc[int(idx)]
            pair = {
                'index': int(idx),
                'SMILES_1': row.get('SMILES_1'),
                'Activity_1': float(row.get('Activity_1')) if row.get('Activity_1') is not None else None,
                'SMILES_2': row.get('SMILES_2'),
                'Activity_2': float(row.get('Activity_2')) if row.get('Activity_2') is not None else None,
                'Similarity': float(row.get('Similarity')) if 'Similarity' in row else None,
                'Activity_Diff': float(row.get('Activity_Diff')) if 'Activity_Diff' in row else None,
            }
        except Exception:
            pair = None

    if pair:
        st.subheader("ì„ íƒëœ ë¶„ì ìŒ")

        smiles1 = pair.get('SMILES_1')
        activity1 = pair.get('Activity_1')
        smiles2 = pair.get('SMILES_2')
        activity2 = pair.get('Activity_2')
        similarity = pair.get('Similarity')
        activity_diff = pair.get('Activity_Diff')

        meta_line = []
        if similarity is not None:
            meta_line.append(f"ìœ ì‚¬ë„: {similarity:.3f}")
        if activity_diff is not None:
            meta_line.append(f"í™œì„±ë„ ì°¨ì´: {activity_diff:.2f}")
        st.caption(" Â· ".join(meta_line))

        # êµ¬ì¡° ì´ë¯¸ì§€ ë° SMILES/í™œì„± í‘œì‹œ
        try:
            legend1 = f"Mol 1 (Activity: {activity1:.2f})" if activity1 is not None else "Mol 1"
            legend2 = f"Mol 2 (Activity: {activity2:.2f})" if activity2 is not None else "Mol 2"
            img = visualize_structure_difference(smiles1, smiles2, legend1, legend2)
            st.image(img, use_container_width=True)
        except Exception as e:
            st.warning(f"êµ¬ì¡° ì´ë¯¸ì§€ë¥¼ ë Œë”ë§í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")

        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**í™”í•©ë¬¼ 1 (Molecule 1)**")
            if smiles1:
                st.code(smiles1, language='smiles')
            if activity1 is not None:
                st.metric("Activity", f"{activity1:.2f}")
        with c2:
            st.markdown("**í™”í•©ë¬¼ 2 (Molecule 2)**")
            if smiles2:
                st.code(smiles2, language='smiles')
            if activity2 is not None:
                st.metric("Activity", f"{activity2:.2f}")

        st.markdown("---")
        st.info("ì´ ìŒì„ ê¸°ë°˜ìœ¼ë¡œ LLM ê°€ì„¤ ìƒì„±ì„ ì´ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ê°€ì„¤ ìƒì„± ì…ë ¥ê³¼ ì‹¤í–‰
        st.subheader("ê°€ì„¤ ìƒì„±")
        struct_desc = st.text_area(
            "êµ¬ì¡° ì°¨ì´ ìš”ì•½ (ì„ íƒ)",
            placeholder="ë‘ ë¶„ì ê°„ êµ¬ì¡°ì  ì°¨ì´ë¥¼ ê°„ë‹¨íˆ ì ì–´ì£¼ì„¸ìš” (ì˜ˆ: thioether â†’ sulfoxide ì‚°í™”, ì „ì ëŒê°œ ì¦ê°€ ë“±)",
            key="structural_difference_description",
            height=80,
        )

        if st.button("ê°€ì„¤ ìƒì„±", type="primary", key="btn_generate_hypothesis"):
            _reset_token_usage()
            openai_api_key = get_openai_api_key_from_file()
            if not openai_api_key:
                st.warning("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ 'openAI_key.txt' ë˜ëŠ” 'base/openAI_key.txt'ì— í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
            else:
                try:
                    with st.spinner("LLMì´ ê°€ì„¤ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        gen_result = generate_hypothesis(
                            api_key=openai_api_key,
                            smiles1=smiles1,
                            activity1=activity1 if activity1 is not None else 0.0,
                            smiles2=smiles2,
                            activity2=activity2 if activity2 is not None else 0.0,
                            structural_difference_description=struct_desc or "",
                            similarity=similarity if similarity is not None else 0.0,
                        )
                    # ê²°ê³¼ ì €ì¥ (ì„¸ì…˜)
                    st.session_state['generated_hypothesis_raw'] = gen_result.get('content', '')
                    _add_token_usage('generation', gen_result.get('model', 'unknown'), gen_result.get('usage', {}))
                    _show_last_and_total_tokens()
                    # JSON íŒŒì‹± ë° ë§ˆí¬ë‹¤ìš´ ë³€í™˜
                    try:
                        data = json.loads(st.session_state['generated_hypothesis_raw'])
                        md = format_hypothesis_for_markdown(data)
                        st.session_state['generated_hypothesis_md'] = md
                    except json.JSONDecodeError:
                        st.error("LLM ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤. ì›ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.")
                        st.text(st.session_state['generated_hypothesis_raw'][:4000])
                except Exception as e:
                    st.error(f"ê°€ì„¤ ìƒì„± í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")

        # ìƒì„± ê²°ê³¼ í‘œì‹œ
        if 'generated_hypothesis_md' in st.session_state:
            st.subheader("ìƒì„±ëœ ê°€ì„¤")
            st.markdown(st.session_state['generated_hypothesis_md'], unsafe_allow_html=True)

            # ì €ì¥
            st.markdown("---")
            st.subheader("ê°€ì„¤ ì €ì¥")
            default_name = f"hyp_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_idx{pair.get('index', 0)}.md"
            filename = st.text_input("íŒŒì¼ëª…", value=default_name, key="gen_save_filename")
            if st.button("íŒŒì¼ë¡œ ì €ì¥", key="btn_save_generated_hypothesis"):
                try:
                    a1 = float(activity1) if activity1 is not None else 0.0
                    a2 = float(activity2) if activity2 is not None else 0.0
                    header = (
                        f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n"
                        f"- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{smiles1}` (í™œì„±ë„: {a1:.2f})\n"
                        f"- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{smiles2}` (í™œì„±ë„: {a2:.2f})\n\n---\n"
                    )
                    content_to_save = header + st.session_state['generated_hypothesis_md']
                    save_path = os.path.join("hypotheses", filename)
                    save_hypothesis_to_md(content_to_save, save_path)
                    st.success(f"ê°€ì„¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")
                except Exception as e:
                    st.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

        # ì„ íƒ ì·¨ì†Œ ë²„íŠ¼ (í•„ìš” ì‹œ)
        if st.button("ì„ íƒ í•´ì œ"):
            for k in ['selected_cliff_pair', 'selected_cliff_index']:
                if k in st.session_state:
                    del st.session_state[k]
            st.rerun()
    else:
        st.info("2. Activity Cliff ë¶„ì„ íƒ­ì—ì„œ ë¶„ì„í•  ìŒì„ 'ì„ íƒí•˜ê¸°' ë²„íŠ¼ìœ¼ë¡œ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")

with tab4:
    st.header("ğŸ“œ ì €ì¥ëœ ê°€ì„¤ ê´€ë¦¬ (ë³´ê¸°/ë‹¤ìš´ë¡œë“œ)")
    hypotheses_dir = "hypotheses"

    if st.button("ğŸ”„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("ì•„ì§ ì €ì¥ëœ ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        if not files:
            st.info("ì €ì¥ëœ ê°€ì„¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            selected_file = st.selectbox("í™•ì¸í•  ê°€ì„¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:", files)

            if selected_file:
                filepath = os.path.join(hypotheses_dir, selected_file)
                try:
                    with open(filepath, "r", encoding="utf-8") as file:
                        content = file.read()
                    
                    st.markdown("---")
                    st.subheader(f"ğŸ“„ {selected_file}")
                    st.markdown(content, unsafe_allow_html=True)

                    st.download_button(
                        label=f"'{selected_file}' ë‹¤ìš´ë¡œë“œ",
                        data=content,
                        file_name=selected_file,
                        mime="text/markdown"
                    )

                except Exception as e:
                    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

with tab5:
    st.header("ğŸ”„ ê°€ì„¤ í‰ê°€ ë° ìˆ˜ì •")
    hypotheses_dir = "hypotheses"

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("í‰ê°€í•  ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        hypothesis_files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        # --- 1. ê°€ì„¤ íŒŒì¼ ëª©ë¡ í‘œì‹œ ---
        st.subheader("ğŸ“‹ ê°€ì„¤ ëª©ë¡")
        selected_file = st.radio(
            "í‰ê°€í•  ê°€ì„¤ì„ ì„ íƒí•˜ì„¸ìš”:", 
            hypothesis_files, 
            key="selected_hypothesis_file",
            label_visibility="collapsed"
        )
        st.markdown("---")

        # --- 2. ì„ íƒëœ ê°€ì„¤ ë‚´ìš© ë° í‰ê°€/ìˆ˜ì • ---
        if selected_file:
            st.subheader(f"ğŸ“„ ì›ë³¸ ê°€ì„¤: {selected_file}")
            filepath = os.path.join(hypotheses_dir, selected_file)

            try:
                with open(filepath, "r", encoding="utf-8") as file:
                    content = file.read()
                
                parsed_data = parse_hypothesis_md(content)
                if not all(parsed_data.values()):
                    st.error(f"íŒŒì¼({selected_file})ì—ì„œ ë¶„ì ì •ë³´ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.stop()

                # ì›ë³¸ ê°€ì„¤ í‘œì‹œ
                st.markdown(content, unsafe_allow_html=True)
                st.markdown("---")

                # --- ê°€ì„¤ í‰ê°€ ---
                eval_container = st.container(border=True)
                with eval_container:
                    st.subheader("ğŸ”¬ ê°€ì„¤ í‰ê°€")
                    eval_key = f"eval_{selected_file}"
                    
                    if st.button("ê°€ì„¤ í‰ê°€ ì‹¤í–‰", key=f"eval_btn_{selected_file}"):
                        _reset_token_usage()
                        openai_api_key = get_openai_api_key_from_file()
                        if not openai_api_key:
                            st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                        else:
                            with st.spinner("LLMì´ ê°€ì„¤ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                                eval_result = evaluate_hypothesis(
                                    api_key=openai_api_key,
                                    hypothesis_text=parsed_data['hypothesis_body'],
                                    smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                    smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                    structural_difference_description=""
                                )
                                _add_token_usage('evaluation', eval_result.get('model', 'unknown'), eval_result.get('usage', {}))
                                _show_last_and_total_tokens()
                                st.session_state[eval_key] = eval_result.get('content', '')
                                # ìƒˆë¡œìš´ í‰ê°€ê°€ ì‹œì‘ë˜ë©´ ì´ì „ ìˆ˜ì • ê²°ê³¼ëŠ” ì‚­ì œ
                                if f"revise_{selected_file}" in st.session_state:
                                    del st.session_state[f"revise_{selected_file}"]
                    
                    if eval_key in st.session_state:
                        st.markdown("##### í‰ê°€ ê²°ê³¼")
                        try:
                            eval_data = json.loads(st.session_state[eval_key])
                            formatted_eval_md = format_evaluation_for_markdown(eval_data)
                            st.markdown(formatted_eval_md, unsafe_allow_html=True)

                            # í‰ê°€ ê²°ê³¼ ì €ì¥ ì„¹ì…˜
                            st.markdown("---")
                            evaluations_dir = "evaluations"
                            os.makedirs(evaluations_dir, exist_ok=True)
                            
                            base_filename = selected_file.replace(".md", "")
                            eval_filename = f"{base_filename}_Eval.md"
                            
                            content_to_save = f"# ì›ë³¸ ê°€ì„¤: {selected_file}\n\n{content}\n\n---\n\n# ê°€ì„¤ í‰ê°€ ê²°ê³¼\n\n{formatted_eval_md}"
                            eval_filepath = os.path.join(evaluations_dir, eval_filename)
                            save_hypothesis_to_md(content_to_save, eval_filepath)
                            st.success(f"í‰ê°€ ê²°ê³¼ê°€ '{eval_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.toast("í‰ê°€ ì €ì¥ ì™„ë£Œ!")

                        except json.JSONDecodeError:
                            st.error("LLM í‰ê°€ ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
                            st.text(st.session_state[eval_key])

                # --- ê°€ì„¤ ìˆ˜ì • ë° ì €ì¥ ---
                if eval_key in st.session_state:
                    revise_container = st.container(border=True)
                    with revise_container:
                        st.subheader("âœï¸ í‰ê°€ ê¸°ë°˜ ê°€ì„¤ ìˆ˜ì •")
                        revise_key = f"revise_{selected_file}"

                        if st.button("í‰ê°€ ê¸°ë°˜ìœ¼ë¡œ ê°€ì„¤ ìˆ˜ì •", key=f"revise_btn_{selected_file}"):
                            openai_api_key = get_openai_api_key_from_file()
                            if not openai_api_key:
                                st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                            else:
                                with st.spinner("LLMì´ ê°€ì„¤ì„ ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."):
                                    revise_result = revise_hypothesis(
                                        api_key=openai_api_key,
                                        original_hypothesis_text=parsed_data['hypothesis_body'],
                                        review_findings=st.session_state[eval_key],
                                        smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                        smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                        structural_difference_description=""
                                    )
                                    _add_token_usage('revision', revise_result.get('model', 'unknown'), revise_result.get('usage', {}))
                                    _show_last_and_total_tokens()
                                    st.session_state[revise_key] = revise_result.get('content', '')
                        
                        if revise_key in st.session_state:
                            st.markdown("##### ìˆ˜ì •ëœ ê°€ì„¤")
                            try:
                                revised_data = json.loads(st.session_state[revise_key])
                                display_md = format_hypothesis_for_markdown(revised_data)
                                st.markdown(display_md, unsafe_allow_html=True)

                                # ìˆ˜ì •ëœ ê°€ì„¤ ì €ì¥ ì„¹ì…˜
                                st.markdown("---")
                                st.subheader("ğŸ’¾ ìˆ˜ì •ëœ ê°€ì„¤ ì €ì¥")
                                
                                file_header = f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{parsed_data['smiles1']}` (í™œì„±ë„: {parsed_data['activity1']:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{parsed_data['smiles2']}` (í™œì„±ë„: {parsed_data['activity2']:.2f})\n\n---"
                                final_md_to_save = file_header + display_md

                                new_filename = f"revised_{selected_file}"
                                new_filepath = os.path.join(hypotheses_dir, new_filename)
                                save_hypothesis_to_md(final_md_to_save, new_filepath)
                                st.success(f"ìˆ˜ì •ëœ ê°€ì„¤ì´ '{new_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.toast("ì €ì¥ ì™„ë£Œ!")

                            except json.JSONDecodeError:
                                st.error("LLM ìˆ˜ì • ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
                                st.text(st.session_state[revise_key])

            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

with tab6:
    st.header("ğŸ¤– ìë™ ê°€ì„¤ ìˆ˜ì •")
    hypotheses_dir = "hypotheses"

    if not os.path.isdir(hypotheses_dir) or not os.listdir(hypotheses_dir):
        st.info("ìë™ ìˆ˜ì •í•  ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. 3. ê°€ì„¤ ìƒì„± íƒ­ì—ì„œ ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        hypothesis_files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
        
        selected_file_auto = st.selectbox(
            "ìë™ ìˆ˜ì •ì„ ì‹œì‘í•  ê°€ì„¤ì„ ì„ íƒí•˜ì„¸ìš”:", 
            hypothesis_files, 
            key="selected_hypothesis_file_auto"
        )
        
        col1, col2 = st.columns(2)
        with col1:
            min_iterations = st.number_input("ìµœì†Œ ë°˜ë³µ íšŸìˆ˜:", min_value=1, max_value=10, value=1, step=1)
        with col2:
            max_iterations = st.number_input("ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜:", min_value=1, max_value=20, value=20, step=1)

        if st.button("ğŸ¤– ìë™ ìˆ˜ì • ì‹œì‘", key="auto_revise_start"):
            _reset_token_usage()
            openai_api_key = get_openai_api_key_from_file()
            if not openai_api_key:
                st.warning("API í‚¤ë¥¼ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                st.stop()

            filepath = os.path.join(hypotheses_dir, selected_file_auto)
            try:
                with open(filepath, "r", encoding="utf-8") as file:
                    content = file.read()
                
                parsed_data = parse_hypothesis_md(content)
                if not all(parsed_data.values()):
                    st.error(f"íŒŒì¼({selected_file_auto})ì—ì„œ ë¶„ì ì •ë³´ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.stop()

            except Exception as e:
                st.error(f"ì›ë³¸ ê°€ì„¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.stop()

            current_hypothesis_body = parsed_data['hypothesis_body']
            final_hypothesis_body = ""

            with st.status(f"'{selected_file_auto}'ì— ëŒ€í•œ ìë™ ìˆ˜ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...", expanded=True) as status:
                for i in range(max_iterations):
                    st.write("---")
                    st.write(f"**ğŸš€ ë°˜ë³µ {i+1}/{max_iterations}**")
                    
                    # 1. í‰ê°€
                    st.write("1ï¸âƒ£ ê°€ì„¤ì„ í‰ê°€í•©ë‹ˆë‹¤...")
                    try:
                        eval_result = evaluate_hypothesis(
                            api_key=openai_api_key,
                            hypothesis_text=current_hypothesis_body,
                            smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                            smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                            structural_difference_description=""
                        )
                        _add_token_usage('evaluation', eval_result.get('model', 'unknown'), eval_result.get('usage', {}))
                        _show_last_and_total_tokens()
                        eval_content = eval_result.get('content', '')
                        eval_data = json.loads(eval_content)
                        verdict = eval_data.get('summary', {}).get('verdict', 'Unknown').upper()
                        
                        with st.expander("í‰ê°€ ê²°ê³¼ ë³´ê¸°"):
                            st.markdown(format_evaluation_for_markdown(eval_data), unsafe_allow_html=True)

                    except Exception as e:
                        st.error(f"ë°˜ë³µ {i+1}ì—ì„œ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        status.update(label="ì˜¤ë¥˜ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨", state="error")
                        st.stop()

                    # 2. íŒì •ì— ë”°ë¥¸ ë¶„ê¸°
                    st.write(f"2ï¸âƒ£ í‰ê°€ íŒì •: **{verdict}**")
                    if ("GOOD" in verdict or "SOUND" in verdict) and (i + 1) >= min_iterations:
                        st.success(f"âœ… ê°€ì„¤ì´ 'Good' ë˜ëŠ” 'Unsound'ë¡œ íŒì •ë˜ê³  ìµœì†Œ ë°˜ë³µ íšŸìˆ˜({min_iterations})ì— ë„ë‹¬í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        final_hypothesis_body = current_hypothesis_body
                        status.update(label="ìë™ ìˆ˜ì • ì™„ë£Œ!", state="complete")
                        break
                    
                    elif "WEAK" in verdict:
                        st.info("ğŸ¤” ê°€ì„¤ì´ 'Weak'ë¡œ íŒì •ë˜ì–´ ìˆ˜ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                        # 3. ìˆ˜ì •
                        st.write("3ï¸âƒ£ í‰ê°€ ê¸°ë°˜ìœ¼ë¡œ ê°€ì„¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤...")
                        try:
                            revise_result = revise_hypothesis(
                                api_key=openai_api_key,
                                original_hypothesis_text=current_hypothesis_body,
                                review_findings=eval_content,
                                smiles1=parsed_data['smiles1'], activity1=parsed_data['activity1'],
                                smiles2=parsed_data['smiles2'], activity2=parsed_data['activity2'],
                                structural_difference_description=""
                            )
                            _add_token_usage('revision', revise_result.get('model', 'unknown'), revise_result.get('usage', {}))
                            _show_last_and_total_tokens()
                            revised_data = json.loads(revise_result.get('content', ''))
                            current_hypothesis_body = format_hypothesis_for_markdown(revised_data)
                            
                            with st.expander("ìˆ˜ì •ëœ ê°€ì„¤ ë‚´ìš© ë³´ê¸°"):
                                st.markdown(current_hypothesis_body, unsafe_allow_html=True)

                        except Exception as e:
                            st.error(f"ë°˜ë³µ {i+1}ì—ì„œ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            status.update(label="ì˜¤ë¥˜ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨", state="error")
                            st.stop()
                    else:
                        st.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íŒì •('{verdict}')ìœ¼ë¡œ ì¸í•´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        final_hypothesis_body = current_hypothesis_body
                        status.update(label="ì•Œ ìˆ˜ ì—†ëŠ” íŒì •ìœ¼ë¡œ ì¤‘ë‹¨ë¨", state="error")
                        break
                
                else: # for-else loop: break ì—†ì´ ëë‚¬ì„ ê²½ìš°
                    st.warning(f"ğŸ”” ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                    final_hypothesis_body = current_hypothesis_body
                    status.update(label="ìµœëŒ€ ë°˜ë³µ í›„ ì™„ë£Œ", state="complete")

            # ìµœì¢… ê²°ê³¼ ì €ì¥
            if final_hypothesis_body:
                st.markdown("---")
                st.subheader("ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥")
                
                file_header = f"**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{parsed_data['smiles1']}` (í™œì„±ë„: {parsed_data['activity1']:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{parsed_data['smiles2']}` (í™œì„±ë„: {parsed_data['activity2']:.2f})\n\n---"
                final_md_to_save = file_header + final_hypothesis_body

                # ìƒˆ íŒŒì¼ëª… ìƒì„±
                base_name = selected_file_auto.replace('.md', '')
                if base_name.startswith('auto_'): # ê¸°ì¡´ ì ‘ë‘ì‚¬ ì œê±°
                    base_name = base_name[5:]
                
                new_filename = f"auto_{base_name}.md"
                new_filepath = os.path.join(hypotheses_dir, new_filename)
                
                save_hypothesis_to_md(final_md_to_save, new_filepath)
                st.success(f"ìµœì¢… ìˆ˜ì •ëœ ê°€ì„¤ì´ '{new_filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                st.markdown("##### ìµœì¢… ê°€ì„¤ ë‚´ìš©:")
                st.markdown(final_md_to_save, unsafe_allow_html=True)
