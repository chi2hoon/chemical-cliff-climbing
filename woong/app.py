import streamlit as st
import pandas as pd
import datetime
import os
import json
import zipfile
import io
from modules.cheminformatics import find_activity_cliffs
from modules.visualization import visualize_structure_difference
from modules.llm_handler import generate_hypothesis
from modules.io_utils import load_smiles_activity_csv, save_hypothesis_to_md

# --- Helper Functions ---

def get_openai_api_key_from_file():
    try:
        with open("openAI_key.txt", "r") as f:
            return f.read().strip()
    except FileNotFoundError:
        return None

def format_hypothesis_for_markdown(data: dict) -> str:
    """ì£¼ì–´ì§„ ê°€ì„¤ ë°ì´í„°(dict)ë¥¼ ê°€ë…ì„± ì¢‹ì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    md_lines = []

    # ê¸°ë³¸ ì •ë³´
    md_lines.append(f"### ğŸ† ì£¼ìš” ê°€ì„¤: {data.get('primary_hypothesis', 'N/A')}")
    md_lines.append(f"- **ë” í™œì„±ì´ ë†’ì€ í™”í•©ë¬¼:** `{data.get('more_active', 'N/A')}`")
    md_lines.append(f"- **í™œì„±ë„ ë³€í™” ì„¤ëª…:** {data.get('delta_pAct_explained', 'N/A')}")
    md_lines.append(f"- **ì‹ ë¢°ë„:** {data.get('confidence', 0.0) * 100:.1f}%")
    md_lines.append("\n")

    # ê¸°ì „ ë¶„ì„
    md_lines.append("### ğŸ”¬ ê¸°ì „ ë¶„ì„")
    rationale = data.get('mechanistic_rationale', {})
    for key, value in rationale.items():
        if value and value not in ["N/A", "ì„ íƒ"]:
            md_lines.append(f"- **{key.replace('_', ' ').title()}:** {value}")
    md_lines.append("\n")

    # ì„¤ê³„ ì œì•ˆ
    md_lines.append("### ğŸ’¡ ê²€ì¦ì„ ìœ„í•œ ë¶„ì ì„¤ê³„ ì œì•ˆ")
    suggestions = data.get('design_suggestions', [])
    if suggestions:
        df = pd.DataFrame(suggestions)
        md_lines.append(df.to_markdown(index=False))
    md_lines.append("\n")

    # ë°˜ëŒ€ ê°€ì„¤
    md_lines.append("### ğŸ¤” ë°˜ëŒ€ ê°€ì„¤")
    counter_hypotheses = data.get('counter_hypotheses', [])
    for i, counter in enumerate(counter_hypotheses, 1):
        md_lines.append(f"{i}. {counter}")
    md_lines.append("\n")

    # ADMET ìœ„í—˜ì„±
    md_lines.append("### âš ï¸ ADMET ìœ„í—˜ì„± ì˜ˆì¸¡")
    admet_flags = data.get('admet_flags', [])
    for flag in admet_flags:
        md_lines.append(f"- {flag}")
    md_lines.append("\n")
    
    # ê°€ì • ë° í•œê³„
    md_lines.append("### ğŸ“‹ ê°€ì • ë° í•œê³„")
    assumptions = data.get('assumptions_and_limits', [])
    for assumption in assumptions:
        md_lines.append(f"- {assumption}")

    return "\n".join(md_lines)


# --- Streamlit App ---

st.set_page_config(layout="wide")
st.title("ğŸ”¬ SAR ë¶„ì„ ë° ê°€ì„¤ ìƒì„± ìë™í™” ë„êµ¬")
st.write("ë¶„ì êµ¬ì¡°ì™€ í™œì„± ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì¡°-í™œì„± ê´€ê³„(SAR) ë¶„ì„ ë° ê°€ì„¤ ìƒì„±ì„ ìë™í™”í•©ë‹ˆë‹¤.")

# --- 1. ë°ì´í„° ì—…ë¡œë“œ ---
st.header("1. ë°ì´í„° ì—…ë¡œë“œ")

uploaded_file = st.file_uploader("ë¶„ì êµ¬ì¡°(SMILES)ì™€ í™œì„± ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="csv")

if uploaded_file is not None:
    try:
        df, suggestion = load_smiles_activity_csv(uploaded_file)
        st.success("íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"CSV ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        df = None

    if df is not None:
        st.subheader("ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df.head())
        st.caption("ìë™ ì¸ì‹ëœ ì»¬ëŸ¼ ì œì•ˆê°’ì„ í™•ì¸í•˜ì„¸ìš”. í•„ìš” ì‹œ ë³€ê²½ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        st.session_state['auto_suggestion'] = suggestion

    st.session_state['df'] = df

# --- 2. Activity Cliff ë¶„ì„ ì„¤ì • ---
st.header("2. Activity Cliff ë¶„ì„")

if 'df' in st.session_state and st.session_state['df'] is not None:
    df = st.session_state['df']
    
    col1, col2 = st.columns(2)
    with col1:
        auto = st.session_state.get('auto_suggestion', {})
        smiles_col_default = auto.get('smiles_col') if auto.get('smiles_col') in df.columns else None
        activity_col_default = auto.get('activity_col') if auto.get('activity_col') in df.columns else None

        smiles_col = st.selectbox("SMILES ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:", df.columns, index=(list(df.columns).index(smiles_col_default) if smiles_col_default else 0))
        activity_col = st.selectbox("í™œì„±ë„ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:", df.columns, index=(list(df.columns).index(activity_col_default) if activity_col_default else (1 if len(df.columns) > 1 else 0)))

    with col2:
        similarity_threshold = st.slider("êµ¬ì¡° ìœ ì‚¬ë„ ì„ê³„ê°’ (Tanimoto)", 0.7, 1.0, 0.85, 0.01)
        activity_diff_threshold = st.number_input("í™œì„±ë„ ì°¨ì´ ì„ê³„ê°’", min_value=0.0, value=1.0, step=0.1)

    if st.button("Activity Cliff ë¶„ì„ ì‹¤í–‰"):
        with st.spinner("Activity Cliffë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            work_df = df.copy()
            work_df = work_df.dropna(subset=[activity_col])
            work_df = work_df.reset_index(drop=True)
            
            cliff_df = find_activity_cliffs(
                work_df,
                smiles_col=smiles_col,
                activity_col=activity_col,
                similarity_threshold=similarity_threshold,
                activity_diff_threshold=activity_diff_threshold
            )
        
        st.success(f"{len(cliff_df)}ê°œì˜ Activity Cliff ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        st.dataframe(cliff_df)
        st.session_state['cliff_df'] = cliff_df

# --- 3. ê²°ê³¼ ì‹œê°í™” ë° ê°€ì„¤ ìƒì„± ---
st.header("3. ê²°ê³¼ ì‹œê°í™” ë° ê°€ì„¤ ìƒì„±")
if 'cliff_df' in st.session_state and not st.session_state['cliff_df'].empty:
    cliff_df = st.session_state['cliff_df']
    
    selected_indices = st.multiselect("ë¶„ì„ ë° ì‹œê°í™”í•  Activity Cliff ìŒì„ ì„ íƒí•˜ì„¸ìš”:", cliff_df.index)
    
    if selected_indices:
        openai_api_key = get_openai_api_key_from_file()
        if not openai_api_key:
            st.warning("LLM ê°€ì„¤ ìƒì„±ì„ ìœ„í•´ openAI_key.txt íŒŒì¼ì— API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state['openai_api_key'] = openai_api_key
            st.success("API í‚¤ê°€ openAI_key.txt íŒŒì¼ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

            if st.button("ì„ íƒëœ ìŒì— ëŒ€í•œ ê°€ì„¤ ìƒì„±"):
                output_dir = "hypotheses"
                os.makedirs(output_dir, exist_ok=True)

                for i in selected_indices:
                    row = cliff_df.loc[i]
                    st.subheader(f"ë¶„ì„ ìŒ #{i}")
                    
                    # ì‹œê°í™”
                    img = visualize_structure_difference(
                        smiles1=row['SMILES_1'],
                        smiles2=row['SMILES_2'],
                        legend1=f"SMILES: {row['SMILES_1']}\nActivity: {row['Activity_1']:.2f}",
                        legend2=f"SMILES: {row['SMILES_2']}\nActivity: {row['Activity_2']:.2f}"
                    )
                    st.image(img, caption=f"ìœ ì‚¬ë„: {row['Similarity']:.3f} | í™œì„±ë„ ì°¨ì´: {row['Activity_Diff']:.2f}")

                    # ê°€ì„¤ ìƒì„±
                    with st.spinner(f"ìŒ #{i}ì— ëŒ€í•œ LLM ê°€ì„¤ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        if row['Activity_1'] > row['Activity_2']:
                            high_act_smiles, high_act_val = row['SMILES_1'], row['Activity_1']
                            low_act_smiles, low_act_val = row['SMILES_2'], row['Activity_2']
                        else:
                            high_act_smiles, high_act_val = row['SMILES_2'], row['Activity_2']
                            low_act_smiles, low_act_val = row['SMILES_1'], row['Activity_1']

                        json_response = generate_hypothesis(
                            api_key=openai_api_key,
                            smiles1=low_act_smiles,
                            activity1=low_act_val,
                            smiles2=high_act_smiles,
                            activity2=high_act_val,
                            structural_difference_description=f"í™”í•©ë¬¼ 1({low_act_smiles})ê³¼ í™”í•©ë¬¼ 2({high_act_smiles})ì˜ êµ¬ì¡°ì  ì°¨ì´ì ."
                        )
                        
                        try:
                            hypothesis_data = json.loads(json_response)
                            
                            display_md = format_hypothesis_for_markdown(hypothesis_data)
                            
                            file_header = f"""**ë¶„ì„ ëŒ€ìƒ ë¶„ì:**\n- **í™”í•©ë¬¼ 1 (ìƒëŒ€ì  ì €í™œì„±):** `{low_act_smiles}` (í™œì„±ë„: {low_act_val:.2f})\n- **í™”í•©ë¬¼ 2 (ìƒëŒ€ì  ê³ í™œì„±):** `{high_act_smiles}` (í™œì„±ë„: {high_act_val:.2f})\n\n---\n"""
                            file_md = file_header + display_md

                            st.markdown(file_md, unsafe_allow_html=True)

                            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                            filename = f"hypothesis_pair_{i}_{timestamp}.md"
                            filepath = os.path.join(output_dir, filename)
                            save_hypothesis_to_md(file_md, filepath)
                            st.success(f"ê°€ì„¤ì´ '{filepath}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                        except json.JSONDecodeError:
                            st.error("LLM ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì›ë³¸ ì‘ë‹µì„ í‘œì‹œí•©ë‹ˆë‹¤:")
                            st.text(json_response)

# --- 4. ì €ì¥ëœ ê°€ì„¤ ê´€ë¦¬ (ë³´ê¸°/ë‹¤ìš´ë¡œë“œ) ---
st.header("ğŸ“œ ì €ì¥ëœ ê°€ì„¤ ê´€ë¦¬ (ë³´ê¸°/ë‹¤ìš´ë¡œë“œ)")

hypotheses_dir = "hypotheses"

if not os.path.isdir(hypotheses_dir):
    st.info("ì•„ì§ ì €ì¥ëœ ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. ê°€ì„¤ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
else:
    files = sorted([f for f in os.listdir(hypotheses_dir) if f.endswith(".md")], reverse=True)
    
    if not files:
        st.info("ì €ì¥ëœ ê°€ì„¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        selected_files_to_download = {}
        
        for f in files:
            with st.expander(f):
                # ì²´í¬ë°•ìŠ¤ë¥¼ expander ì•ˆì— ë°°ì¹˜
                selected_files_to_download[f] = st.checkbox("ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ì„ íƒ", key=f"dl_{f}")
                
                # íŒŒì¼ ë‚´ìš© ì½ê³  í‘œì‹œ
                try:
                    with open(os.path.join(hypotheses_dir, f), "r", encoding="utf-8") as file:
                        content = file.read()
                    st.markdown(content, unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì€ íŒŒì¼ ëª©ë¡ ë£¨í”„ ë°”ê¹¥ì— ìœ„ì¹˜
        if st.button("ì„ íƒëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"):
            files_to_zip = [f for f, selected in selected_files_to_download.items() if selected]
            
            if not files_to_zip:
                st.warning("ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì„ ë¨¼ì € ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                zip_buffer = io.BytesIO()
                with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
                    for f in files_to_zip:
                        file_path = os.path.join(hypotheses_dir, f)
                        zip_file.write(file_path, f)
                
                st.download_button(
                    label="ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=zip_buffer.getvalue(),
                    file_name="hypotheses.zip",
                    mime="application/zip"
                )